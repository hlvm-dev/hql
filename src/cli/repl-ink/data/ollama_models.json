{
  "version": "2.0",
  "last_updated": "2026-01-12",
  "total_models": 205,
  "models": [
    {
      "description": "Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and 405B parameter sizes.",
      "id": "llama3.1",
      "name": "Llama3.1",
      "variants": [
        {
          "id": "llama3.1:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.9GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "llama3.1:405b",
          "name": "405b",
          "parameters": "405B",
          "size": "243GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "llama3.1:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "43GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "llama3.1:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "4.9GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/llama3.1",
      "downloads": 108600000
    },
    {
      "description": "DeepSeek-R1 is a family of open reasoning models with performance approaching that of leading models, such as O3 and Gemini 2.5 Pro.",
      "id": "deepseek-r1",
      "name": "Deepseek R1",
      "variants": [
        {
          "id": "deepseek-r1:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "5.2GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "deepseek-r1:671b",
          "name": "671b",
          "parameters": "671B",
          "size": "404GB",
          "context": "160K",
          "vision": false
        },
        {
          "id": "deepseek-r1:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "43GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "deepseek-r1:32b",
          "name": "32b",
          "parameters": "32B",
          "size": "20GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "deepseek-r1:14b",
          "name": "14b",
          "parameters": "14B",
          "size": "9.0GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "deepseek-r1:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "5.2GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "deepseek-r1:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.7GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "deepseek-r1:1.5b",
          "name": "1.5b",
          "parameters": "1.5B",
          "size": "1.1GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/deepseek-r1",
      "downloads": 76100000
    },
    {
      "description": "Meta's Llama 3.2 goes small with 1B and 3B models. ",
      "id": "llama3.2",
      "name": "Llama3.2",
      "variants": [
        {
          "id": "llama3.2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "2.0GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "llama3.2:3b",
          "name": "3b",
          "parameters": "3B",
          "size": "2.0GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "llama3.2:1b",
          "name": "1b",
          "parameters": "1B",
          "size": "1.3GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/llama3.2",
      "downloads": 52600000
    },
    {
      "description": "A high-performing open embedding model with a large token context window.",
      "id": "nomic-embed-text",
      "name": "Nomic Embed Text",
      "variants": [
        {
          "id": "nomic-embed-text:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "274MB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "nomic-embed-text:137m-v1.5-fp16",
          "name": "137m-v1.5-fp16",
          "parameters": "137M",
          "size": "274MB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "nomic-embed-text:v1.5",
          "name": "v1.5",
          "parameters": "Unknown",
          "size": "274MB",
          "context": "2K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/nomic-embed-text",
      "downloads": 49700000,
      "model_type": "embedding"
    },
    {
      "description": "The current, most capable model that runs on a single GPU.",
      "id": "gemma3",
      "name": "Gemma3",
      "variants": [
        {
          "id": "gemma3:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.3GB",
          "context": "128K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "gemma3:270m",
          "name": "270m",
          "parameters": "270M",
          "size": "292MB",
          "context": "32K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "gemma3:27b",
          "name": "27b",
          "parameters": "27B",
          "size": "17GB",
          "context": "128K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "gemma3:27b-cloud",
          "name": "27b-cloud",
          "parameters": "27B",
          "size": "Cloud (API only)",
          "context": "128K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "gemma3:12b",
          "name": "12b",
          "parameters": "12B",
          "size": "8.1GB",
          "context": "128K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "gemma3:12b-cloud",
          "name": "12b-cloud",
          "parameters": "12B",
          "size": "Cloud (API only)",
          "context": "32K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "gemma3:4b",
          "name": "4b",
          "parameters": "4B",
          "size": "3.3GB",
          "context": "128K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "gemma3:4b-cloud",
          "name": "4b-cloud",
          "parameters": "4B",
          "size": "Cloud (API only)",
          "context": "32K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "gemma3:1b",
          "name": "1b",
          "parameters": "1B",
          "size": "815MB",
          "context": "32K",
          "vision": true,
          "input_types": "Text, Image"
        }
      ],
      "vision": true,
      "ollamaUrl": "https://ollama.com/library/gemma3",
      "downloads": 29600000
    },
    {
      "description": "The 7B model released by Mistral AI, updated to version 0.3.",
      "id": "mistral",
      "name": "Mistral",
      "variants": [
        {
          "id": "mistral:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.4GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "mistral:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.4GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/mistral",
      "downloads": 24000000
    },
    {
      "description": "Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, encompassing up to 18 trillion tokens. The model supports up to 128K tokens and has multilingual support. ",
      "id": "qwen2.5",
      "name": "Qwen2.5",
      "variants": [
        {
          "id": "qwen2.5:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.7GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen2.5:72b",
          "name": "72b",
          "parameters": "72B",
          "size": "47GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen2.5:32b",
          "name": "32b",
          "parameters": "32B",
          "size": "20GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen2.5:14b",
          "name": "14b",
          "parameters": "14B",
          "size": "9.0GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen2.5:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.7GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen2.5:3b",
          "name": "3b",
          "parameters": "3B",
          "size": "1.9GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen2.5:1.5b",
          "name": "1.5b",
          "parameters": "1.5B",
          "size": "986MB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen2.5:0.5b",
          "name": "0.5b",
          "parameters": "0.5B",
          "size": "398MB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/qwen2.5",
      "downloads": 19100000
    },
    {
      "description": "Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.",
      "id": "qwen3",
      "name": "Qwen3",
      "variants": [
        {
          "id": "qwen3:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "5.2GB",
          "context": "40K",
          "vision": false
        },
        {
          "id": "qwen3:235b",
          "name": "235b",
          "parameters": "235B",
          "size": "142GB",
          "context": "256K",
          "vision": false
        },
        {
          "id": "qwen3:32b",
          "name": "32b",
          "parameters": "32B",
          "size": "20GB",
          "context": "40K",
          "vision": false
        },
        {
          "id": "qwen3:30b",
          "name": "30b",
          "parameters": "30B",
          "size": "19GB",
          "context": "256K",
          "vision": false
        },
        {
          "id": "qwen3:14b",
          "name": "14b",
          "parameters": "14B",
          "size": "9.3GB",
          "context": "40K",
          "vision": false
        },
        {
          "id": "qwen3:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "5.2GB",
          "context": "40K",
          "vision": false
        },
        {
          "id": "qwen3:4b",
          "name": "4b",
          "parameters": "4B",
          "size": "2.5GB",
          "context": "256K",
          "vision": false
        },
        {
          "id": "qwen3:1.7b",
          "name": "1.7b",
          "parameters": "1.7B",
          "size": "1.4GB",
          "context": "40K",
          "vision": false
        },
        {
          "id": "qwen3:0.6b",
          "name": "0.6b",
          "parameters": "0.6B",
          "size": "523MB",
          "context": "40K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/qwen3",
      "downloads": 17000000
    },
    {
      "description": "Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art open models by Microsoft.",
      "id": "phi3",
      "name": "Phi3",
      "variants": [
        {
          "id": "phi3:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "2.2GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "phi3:14b",
          "name": "14b",
          "parameters": "14B",
          "size": "7.9GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "phi3:3.8b",
          "name": "3.8b",
          "parameters": "3.8B",
          "size": "2.2GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/phi3",
      "downloads": 15500000
    },
    {
      "description": "Meta Llama 3: The most capable openly available LLM to date",
      "id": "llama3",
      "name": "Llama3",
      "variants": [
        {
          "id": "llama3:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.7GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "llama3:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "40GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "llama3:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "4.7GB",
          "context": "8K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/llama3",
      "downloads": 13600000
    },
    {
      "description": "Google Gemma 2 is a high-performing and efficient model available in three sizes: 2B, 9B, and 27B.",
      "id": "gemma2",
      "name": "Gemma2",
      "variants": [
        {
          "id": "gemma2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "5.4GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "gemma2:27b",
          "name": "27b",
          "parameters": "27B",
          "size": "16GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "gemma2:9b",
          "name": "9b",
          "parameters": "9B",
          "size": "5.4GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "gemma2:2b",
          "name": "2b",
          "parameters": "2B",
          "size": "1.6GB",
          "context": "8K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/gemma2",
      "downloads": 13300000
    },
    {
      "description": "üåã LLaVA is a novel end-to-end trained large multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding. Updated to version 1.6.",
      "id": "llava",
      "name": "Llava",
      "variants": [
        {
          "id": "llava:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.7GB",
          "context": "32K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "llava:34b",
          "name": "34b",
          "parameters": "34B",
          "size": "20GB",
          "context": "4K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "llava:13b",
          "name": "13b",
          "parameters": "13B",
          "size": "8.0GB",
          "context": "4K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "llava:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.7GB",
          "context": "32K",
          "vision": true,
          "input_types": "Text, Image"
        }
      ],
      "vision": true,
      "ollamaUrl": "https://ollama.com/library/llava",
      "downloads": 12500000
    },
    {
      "description": "The latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing.",
      "id": "qwen2.5-coder",
      "name": "Qwen2.5 Coder",
      "variants": [
        {
          "id": "qwen2.5-coder:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.7GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen2.5-coder:32b",
          "name": "32b",
          "parameters": "32B",
          "size": "20GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen2.5-coder:14b",
          "name": "14b",
          "parameters": "14B",
          "size": "9.0GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen2.5-coder:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.7GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen2.5-coder:3b",
          "name": "3b",
          "parameters": "3B",
          "size": "1.9GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen2.5-coder:1.5b",
          "name": "1.5b",
          "parameters": "1.5B",
          "size": "986MB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen2.5-coder:0.5b",
          "name": "0.5b",
          "parameters": "0.5B",
          "size": "398MB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/qwen2.5-coder",
      "downloads": 9800000
    },
    {
      "description": "Phi-4 is a 14B parameter, state-of-the-art open model from Microsoft.",
      "id": "phi4",
      "name": "Phi4",
      "variants": [
        {
          "id": "phi4:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "9.1GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "phi4:14b",
          "name": "14b",
          "parameters": "14B",
          "size": "9.1GB",
          "context": "16K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/phi4",
      "downloads": 6800000
    },
    {
      "description": "State-of-the-art large embedding model from mixedbread.ai",
      "id": "mxbai-embed-large",
      "name": "Mxbai Embed Large",
      "variants": [
        {
          "id": "mxbai-embed-large:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "670MB",
          "context": "512",
          "vision": false
        },
        {
          "id": "mxbai-embed-large:335m",
          "name": "335m",
          "parameters": "335M",
          "size": "670MB",
          "context": "512",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/mxbai-embed-large",
      "downloads": 6400000,
      "model_type": "embedding"
    },
    {
      "description": "OpenAI‚Äôs open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases.",
      "id": "gpt-oss",
      "name": "Gpt Oss",
      "variants": [
        {
          "id": "gpt-oss:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "14GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "gpt-oss:120b",
          "name": "120b",
          "parameters": "120B",
          "size": "65GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "gpt-oss:120b-cloud",
          "name": "120b-cloud",
          "parameters": "120B",
          "size": "Cloud (API only)",
          "context": "128K",
          "vision": false
        },
        {
          "id": "gpt-oss:20b",
          "name": "20b",
          "parameters": "20B",
          "size": "14GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "gpt-oss:20b-cloud",
          "name": "20b-cloud",
          "parameters": "20B",
          "size": "Cloud (API only)",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/gpt-oss",
      "downloads": 5800000
    },
    {
      "description": "Gemma is a family of lightweight, state-of-the-art open models built by Google DeepMind. Updated to version 1.1",
      "id": "gemma",
      "name": "Gemma",
      "variants": [
        {
          "id": "gemma:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "5.0GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "gemma:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "5.0GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "gemma:2b",
          "name": "2b",
          "parameters": "2B",
          "size": "1.7GB",
          "context": "8K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/gemma",
      "downloads": 5700000
    },
    {
      "description": "Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from 0.5B to 110B parameters",
      "id": "qwen",
      "name": "Qwen",
      "variants": [
        {
          "id": "qwen:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "2.3GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen:110b",
          "name": "110b",
          "parameters": "110B",
          "size": "63GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen:72b",
          "name": "72b",
          "parameters": "72B",
          "size": "41GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen:32b",
          "name": "32b",
          "parameters": "32B",
          "size": "18GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen:14b",
          "name": "14b",
          "parameters": "14B",
          "size": "8.2GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.5GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen:4b",
          "name": "4b",
          "parameters": "4B",
          "size": "2.3GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen:1.8b",
          "name": "1.8b",
          "parameters": "1.8B",
          "size": "1.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen:0.5b",
          "name": "0.5b",
          "parameters": "0.5B",
          "size": "395MB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/qwen",
      "downloads": 5300000
    },
    {
      "description": "Llama 2 is a collection of foundation language models ranging from 7B to 70B parameters.",
      "id": "llama2",
      "name": "Llama2",
      "variants": [
        {
          "id": "llama2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.8GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama2:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "39GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama2:13b",
          "name": "13b",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama2:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "3.8GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/llama2",
      "downloads": 5000000
    },
    {
      "description": "Qwen2 is a new series of large language models from Alibaba group",
      "id": "qwen2",
      "name": "Qwen2",
      "variants": [
        {
          "id": "qwen2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.4GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen2:72b",
          "name": "72b",
          "parameters": "72B",
          "size": "41GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen2:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.4GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen2:1.5b",
          "name": "1.5b",
          "parameters": "1.5B",
          "size": "935MB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "qwen2:0.5b",
          "name": "0.5b",
          "parameters": "0.5B",
          "size": "352MB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/qwen2",
      "downloads": 4700000
    },
    {
      "description": "A series of multimodal LLMs (MLLMs) designed for vision-language understanding.",
      "id": "minicpm-v",
      "name": "Minicpm V",
      "variants": [
        {
          "id": "minicpm-v:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "5.5GB",
          "context": "32K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "minicpm-v:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "5.5GB",
          "context": "32K",
          "vision": true,
          "input_types": "Text, Image"
        }
      ],
      "vision": true,
      "ollamaUrl": "https://ollama.com/library/minicpm-v",
      "downloads": 4400000
    },
    {
      "description": "A large language model that can use text prompts to generate and discuss code.",
      "id": "codellama",
      "name": "Codellama",
      "variants": [
        {
          "id": "codellama:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.8GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "codellama:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "39GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "codellama:34b",
          "name": "34b",
          "parameters": "34B",
          "size": "19GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "codellama:13b",
          "name": "13b",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "codellama:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "3.8GB",
          "context": "16K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/codellama",
      "downloads": 3900000
    },
    {
      "description": "Dolphin 3.0 Llama 3.1 8B üê¨ is the next generation of the Dolphin series of instruct-tuned models designed to be the ultimate general purpose local model, enabling coding, math, agentic, function calling, and general use cases.",
      "id": "dolphin3",
      "name": "Dolphin3",
      "variants": [
        {
          "id": "dolphin3:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.9GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "dolphin3:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "4.9GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/dolphin3",
      "downloads": 3600000
    },
    {
      "description": "Llama 3.2 Vision is a collection of instruction-tuned image reasoning generative models in 11B and 90B sizes.",
      "id": "llama3.2-vision",
      "name": "Llama3.2 Vision",
      "variants": [
        {
          "id": "llama3.2-vision:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "7.8GB",
          "context": "128K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "llama3.2-vision:90b",
          "name": "90b",
          "parameters": "90B",
          "size": "55GB",
          "context": "128K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "llama3.2-vision:11b",
          "name": "11b",
          "parameters": "11B",
          "size": "7.8GB",
          "context": "128K",
          "vision": true,
          "input_types": "Text, Image"
        }
      ],
      "vision": true,
      "ollamaUrl": "https://ollama.com/library/llama3.2-vision",
      "downloads": 3600000
    },
    {
      "description": "OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. These models are on par with or better than equivalently sized fully open models, and competitive with open-weight models such as Llama 3.1 on English academic benchmarks.",
      "id": "olmo2",
      "name": "Olmo2",
      "variants": [
        {
          "id": "olmo2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.5GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "olmo2:13b",
          "name": "13b",
          "parameters": "13B",
          "size": "8.4GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "olmo2:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.5GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/olmo2",
      "downloads": 3400000
    },
    {
      "description": "The TinyLlama project is an open endeavor to train a compact 1.1B Llama model on 3 trillion tokens.",
      "id": "tinyllama",
      "name": "Tinyllama",
      "variants": [
        {
          "id": "tinyllama:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "638MB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "tinyllama:1.1b",
          "name": "1.1b",
          "parameters": "1.1B",
          "size": "638MB",
          "context": "2K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/tinyllama",
      "downloads": 3300000
    },
    {
      "description": "A strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.",
      "id": "deepseek-v3",
      "name": "Deepseek V3",
      "variants": [
        {
          "id": "deepseek-v3:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "404GB",
          "context": "160K",
          "vision": false
        },
        {
          "id": "deepseek-v3:671b",
          "name": "671b",
          "parameters": "671B",
          "size": "404GB",
          "context": "160K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/deepseek-v3",
      "downloads": 3200000
    },
    {
      "description": "A state-of-the-art 12B model with 128k context length, built by Mistral AI in collaboration with NVIDIA.",
      "id": "mistral-nemo",
      "name": "Mistral Nemo",
      "variants": [
        {
          "id": "mistral-nemo:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "7.1GB",
          "context": "1000K",
          "vision": false
        },
        {
          "id": "mistral-nemo:12b",
          "name": "12b",
          "parameters": "12B",
          "size": "7.1GB",
          "context": "1000K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/mistral-nemo",
      "downloads": 3200000
    },
    {
      "description": "BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-Functionality, Multi-Linguality, and Multi-Granularity.",
      "id": "bge-m3",
      "name": "Bge M3",
      "variants": [
        {
          "id": "bge-m3:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "1.2GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "bge-m3:567m",
          "name": "567m",
          "parameters": "567M",
          "size": "1.2GB",
          "context": "8K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/bge-m3",
      "downloads": 3000000,
      "model_type": "embedding"
    },
    {
      "description": "New state of the art 70B model. Llama 3.3 70B offers similar performance compared to the Llama 3.1 405B model.",
      "id": "llama3.3",
      "name": "Llama3.3",
      "variants": [
        {
          "id": "llama3.3:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "43GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "llama3.3:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "43GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/llama3.3",
      "downloads": 3000000
    },
    {
      "description": "DeepSeek Coder is a capable coding model trained on two trillion code and natural language tokens.",
      "id": "deepseek-coder",
      "name": "Deepseek Coder",
      "variants": [
        {
          "id": "deepseek-coder:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "776MB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "deepseek-coder:33b",
          "name": "33b",
          "parameters": "33B",
          "size": "19GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "deepseek-coder:6.7b",
          "name": "6.7b",
          "parameters": "6.7B",
          "size": "3.8GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "deepseek-coder:1.3b",
          "name": "1.3b",
          "parameters": "1.3B",
          "size": "776MB",
          "context": "16K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/deepseek-coder",
      "downloads": 2600000
    },
    {
      "description": "Mistral Small 3 sets a new benchmark in the ‚Äúsmall‚Äù Large Language Models category below 70B.",
      "id": "mistral-small",
      "name": "Mistral Small",
      "variants": [
        {
          "id": "mistral-small:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "14GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "mistral-small:24b",
          "name": "24b",
          "parameters": "24B",
          "size": "14GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "mistral-small:22b",
          "name": "22b",
          "parameters": "22B",
          "size": "13GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/mistral-small",
      "downloads": 2300000
    },
    {
      "description": "SmolLM2 is a family of compact language models available in three size: 135M, 360M, and 1.7B parameters.",
      "id": "smollm2",
      "name": "Smollm2",
      "variants": [
        {
          "id": "smollm2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "1.8GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "smollm2:360m",
          "name": "360m",
          "parameters": "360M",
          "size": "726MB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "smollm2:135m",
          "name": "135m",
          "parameters": "135M",
          "size": "271MB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "smollm2:1.7b",
          "name": "1.7b",
          "parameters": "1.7B",
          "size": "1.8GB",
          "context": "8K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/smollm2",
      "downloads": 2300000
    },
    {
      "description": "Embedding models on very large sentence level datasets.",
      "id": "all-minilm",
      "name": "All Minilm",
      "variants": [
        {
          "id": "all-minilm:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "46MB",
          "context": "512",
          "vision": false
        },
        {
          "id": "all-minilm:33m",
          "name": "33m",
          "parameters": "33M",
          "size": "67MB",
          "context": "512",
          "vision": false
        },
        {
          "id": "all-minilm:22m",
          "name": "22m",
          "parameters": "22M",
          "size": "46MB",
          "context": "512",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/all-minilm",
      "downloads": 2200000,
      "model_type": "embedding"
    },
    {
      "description": "A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several benchmarks.",
      "id": "llava-llama3",
      "name": "Llava Llama3",
      "variants": [
        {
          "id": "llava-llama3:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "5.5GB",
          "context": "8K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "llava-llama3:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "5.5GB",
          "context": "8K",
          "vision": true,
          "input_types": "Text, Image"
        }
      ],
      "vision": true,
      "ollamaUrl": "https://ollama.com/library/llava-llama3",
      "downloads": 2100000
    },
    {
      "description": "Alibaba's performant long context models for agentic and coding tasks.",
      "id": "qwen3-coder",
      "name": "Qwen3 Coder",
      "variants": [
        {
          "id": "qwen3-coder:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "19GB",
          "context": "256K",
          "vision": false
        },
        {
          "id": "qwen3-coder:480b",
          "name": "480b",
          "parameters": "480B",
          "size": "290GB",
          "context": "256K",
          "vision": false
        },
        {
          "id": "qwen3-coder:480b-cloud",
          "name": "480b-cloud",
          "parameters": "480B",
          "size": "Cloud (API only)",
          "context": "256K",
          "vision": false
        },
        {
          "id": "qwen3-coder:30b",
          "name": "30b",
          "parameters": "30B",
          "size": "19GB",
          "context": "256K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/qwen3-coder",
      "downloads": 2000000
    },
    {
      "description": "QwQ is the reasoning model of the Qwen series.",
      "id": "qwq",
      "name": "Qwq",
      "variants": [
        {
          "id": "qwq:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "20GB",
          "context": "40K",
          "vision": false
        },
        {
          "id": "qwq:32b",
          "name": "32b",
          "parameters": "32B",
          "size": "20GB",
          "context": "40K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/qwq",
      "downloads": 2000000
    },
    {
      "description": "CodeGemma is a collection of powerful, lightweight models that can perform a variety of coding tasks like fill-in-the-middle code completion, code generation, natural language understanding, mathematical reasoning, and instruction following.",
      "id": "codegemma",
      "name": "Codegemma",
      "variants": [
        {
          "id": "codegemma:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "5.0GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "codegemma:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "5.0GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "codegemma:2b",
          "name": "2b",
          "parameters": "2B",
          "size": "1.6GB",
          "context": "8K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/codegemma",
      "downloads": 1900000
    },
    {
      "description": "A family of efficient AI models under 10B parameters performant in science, math, and coding through innovative training techniques.",
      "id": "falcon3",
      "name": "Falcon3",
      "variants": [
        {
          "id": "falcon3:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.6GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "falcon3:10b",
          "name": "10b",
          "parameters": "10B",
          "size": "6.3GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "falcon3:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.6GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "falcon3:3b",
          "name": "3b",
          "parameters": "3B",
          "size": "2.0GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "falcon3:1b",
          "name": "1b",
          "parameters": "1B",
          "size": "1.8GB",
          "context": "8K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/falcon3",
      "downloads": 1900000
    },
    {
      "description": "The IBM Granite 1B and 3B models are long-context mixture of experts (MoE) Granite models from IBM designed for low latency usage.",
      "id": "granite3.1-moe",
      "name": "Granite3.1 Moe",
      "variants": [
        {
          "id": "granite3.1-moe:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "2.0GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "granite3.1-moe:3b",
          "name": "3b",
          "parameters": "3B",
          "size": "2.0GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "granite3.1-moe:1b",
          "name": "1b",
          "parameters": "1B",
          "size": "1.4GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/granite3.1-moe",
      "downloads": 1900000
    },
    {
      "description": "StarCoder2 is the next generation of transparently trained open code LLMs that comes in three sizes: 3B, 7B and 15B parameters. ",
      "id": "starcoder2",
      "name": "Starcoder2",
      "variants": [
        {
          "id": "starcoder2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "1.7GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "starcoder2:15b",
          "name": "15b",
          "parameters": "15B",
          "size": "9.1GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "starcoder2:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.0GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "starcoder2:3b",
          "name": "3b",
          "parameters": "3B",
          "size": "1.7GB",
          "context": "16K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/starcoder2",
      "downloads": 1800000
    },
    {
      "description": "Uncensored Llama 2 model by George Sung and Jarrad Hope.",
      "id": "llama2-uncensored",
      "name": "Llama2 Uncensored",
      "variants": [
        {
          "id": "llama2-uncensored:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.8GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "llama2-uncensored:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "39GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "llama2-uncensored:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "3.8GB",
          "context": "2K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/llama2-uncensored",
      "downloads": 1600000
    },
    {
      "description": "A set of Mixture of Experts (MoE) model with open weights by Mistral AI in 8x7b and 8x22b parameter sizes.",
      "id": "mixtral",
      "name": "Mixtral",
      "variants": [
        {
          "id": "mixtral:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "26GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "mixtral:8x22b",
          "name": "8x22b",
          "parameters": "22B",
          "size": "80GB",
          "context": "64K",
          "vision": false
        },
        {
          "id": "mixtral:8x7b",
          "name": "8x7b",
          "parameters": "7B",
          "size": "26GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/mixtral",
      "downloads": 1600000
    },
    {
      "description": "A general-purpose model ranging from 3 billion parameters to 70 billion, suitable for entry-level hardware.",
      "id": "orca-mini",
      "name": "Orca Mini",
      "variants": [
        {
          "id": "orca-mini:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "2.0GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "orca-mini:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "39GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "orca-mini:13b",
          "name": "13b",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "orca-mini:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "3.8GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "orca-mini:3b",
          "name": "3b",
          "parameters": "3B",
          "size": "2.0GB",
          "context": "2K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/orca-mini",
      "downloads": 1600000
    },
    {
      "description": "A suite of text embedding models by Snowflake, optimized for performance.",
      "id": "snowflake-arctic-embed",
      "name": "Snowflake Arctic Embed",
      "variants": [
        {
          "id": "snowflake-arctic-embed:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "669MB",
          "context": "512",
          "vision": false
        },
        {
          "id": "snowflake-arctic-embed:335m",
          "name": "335m",
          "parameters": "335M",
          "size": "669MB",
          "context": "512",
          "vision": false
        },
        {
          "id": "snowflake-arctic-embed:137m",
          "name": "137m",
          "parameters": "137M",
          "size": "274MB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "snowflake-arctic-embed:110m",
          "name": "110m",
          "parameters": "110M",
          "size": "219MB",
          "context": "512",
          "vision": false
        },
        {
          "id": "snowflake-arctic-embed:33m",
          "name": "33m",
          "parameters": "33M",
          "size": "67MB",
          "context": "512",
          "vision": false
        },
        {
          "id": "snowflake-arctic-embed:22m",
          "name": "22m",
          "parameters": "22M",
          "size": "46MB",
          "context": "512",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/snowflake-arctic-embed",
      "downloads": 1600000,
      "model_type": "embedding"
    },
    {
      "description": "An open-source Mixture-of-Experts code language model that achieves performance comparable to GPT4-Turbo in code-specific tasks.",
      "id": "deepseek-coder-v2",
      "name": "Deepseek Coder V2",
      "variants": [
        {
          "id": "deepseek-coder-v2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "8.9GB",
          "context": "160K",
          "vision": false
        },
        {
          "id": "deepseek-coder-v2:236b",
          "name": "236b",
          "parameters": "236B",
          "size": "133GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "deepseek-coder-v2:16b",
          "name": "16b",
          "parameters": "16B",
          "size": "8.9GB",
          "context": "160K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/deepseek-coder-v2",
      "downloads": 1400000
    },
    {
      "description": "Cogito v1 Preview is a family of hybrid reasoning models by Deep Cogito that outperform the best available open models of the same size, including counterparts from LLaMA, DeepSeek, and Qwen across most standard benchmarks.",
      "id": "cogito",
      "name": "Cogito",
      "variants": [
        {
          "id": "cogito:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.9GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "cogito:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "43GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "cogito:32b",
          "name": "32b",
          "parameters": "32B",
          "size": "20GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "cogito:14b",
          "name": "14b",
          "parameters": "14B",
          "size": "9.0GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "cogito:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "4.9GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "cogito:3b",
          "name": "3b",
          "parameters": "3B",
          "size": "2.2GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/cogito",
      "downloads": 1100000
    },
    {
      "description": "Flagship vision-language model of Qwen and also a significant leap from the previous Qwen2-VL.",
      "id": "qwen2.5vl",
      "name": "Qwen2.5vl",
      "variants": [
        {
          "id": "qwen2.5vl:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "6.0GB",
          "context": "125K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "qwen2.5vl:72b",
          "name": "72b",
          "parameters": "72B",
          "size": "49GB",
          "context": "125K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "qwen2.5vl:32b",
          "name": "32b",
          "parameters": "32B",
          "size": "21GB",
          "context": "125K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "qwen2.5vl:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "6.0GB",
          "context": "125K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "qwen2.5vl:3b",
          "name": "3b",
          "parameters": "3B",
          "size": "3.2GB",
          "context": "125K",
          "vision": true,
          "input_types": "Text, Image"
        }
      ],
      "vision": true,
      "ollamaUrl": "https://ollama.com/library/qwen2.5vl",
      "downloads": 1100000
    },
    {
      "description": "A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the performance of OpenAI‚Äôs o1-preview with just 1.5B parameters on popular math evaluations.",
      "id": "deepscaler",
      "name": "Deepscaler",
      "variants": [
        {
          "id": "deepscaler:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.6GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "deepscaler:1.5b",
          "name": "1.5b",
          "parameters": "1.5B",
          "size": "3.6GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/deepscaler",
      "downloads": 1000000
    },
    {
      "description": "2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language model by Microsoft Research.",
      "id": "dolphin-phi",
      "name": "Dolphin Phi",
      "variants": [
        {
          "id": "dolphin-phi:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "1.6GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "dolphin-phi:2.7b",
          "name": "2.7b",
          "parameters": "2.7B",
          "size": "1.6GB",
          "context": "2K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/dolphin-phi",
      "downloads": 1000000
    },
    {
      "description": "Gemma 3n models are designed for efficient execution on everyday devices such as laptops, tablets or phones. ",
      "id": "gemma3n",
      "name": "Gemma3n",
      "variants": [
        {
          "id": "gemma3n:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "7.5GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "gemma3n:e4b",
          "name": "e4b",
          "parameters": "4B",
          "size": "7.5GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "gemma3n:e2b",
          "name": "e2b",
          "parameters": "2B",
          "size": "5.6GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/gemma3n",
      "downloads": 1000000
    },
    {
      "description": "Meta's latest collection of multimodal models.",
      "id": "llama4",
      "name": "Llama4",
      "variants": [
        {
          "id": "llama4:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "67GB",
          "context": "10M",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "llama4:16x17b",
          "name": "16x17b",
          "parameters": "17B",
          "size": "67GB",
          "context": "10M",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "llama4:128x17b",
          "name": "128x17b",
          "parameters": "17B",
          "size": "245GB",
          "context": "1M",
          "vision": true,
          "input_types": "Text, Image"
        }
      ],
      "vision": true,
      "ollamaUrl": "https://ollama.com/library/llama4",
      "downloads": 1000000
    },
    {
      "description": "An update to Mistral Small that improves on function calling, instruction following, and less repetition errors.",
      "id": "mistral-small3.2",
      "name": "Mistral Small3.2",
      "variants": [
        {
          "id": "mistral-small3.2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "15GB",
          "context": "128K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "mistral-small3.2:24b",
          "name": "24b",
          "parameters": "24B",
          "size": "15GB",
          "context": "128K",
          "vision": true,
          "input_types": "Text, Image"
        }
      ],
      "vision": true,
      "ollamaUrl": "https://ollama.com/library/mistral-small3.2",
      "downloads": 1000000
    },
    {
      "description": "The most powerful vision-language model in the Qwen model family to date. ",
      "id": "qwen3-vl",
      "name": "Qwen3 Vl",
      "variants": [
        {
          "id": "qwen3-vl:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "6.1GB",
          "context": "256K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "qwen3-vl:235b",
          "name": "235b",
          "parameters": "235B",
          "size": "143GB",
          "context": "256K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "qwen3-vl:235b-cloud",
          "name": "235b-cloud",
          "parameters": "235B",
          "size": "Cloud (API only)",
          "context": "256K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "qwen3-vl:235b-instruct-cloud",
          "name": "235b-instruct-cloud",
          "parameters": "235B",
          "size": "Cloud (API only)",
          "context": "256K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "qwen3-vl:32b",
          "name": "32b",
          "parameters": "32B",
          "size": "21GB",
          "context": "256K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "qwen3-vl:30b",
          "name": "30b",
          "parameters": "30B",
          "size": "20GB",
          "context": "256K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "qwen3-vl:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "6.1GB",
          "context": "256K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "qwen3-vl:4b",
          "name": "4b",
          "parameters": "4B",
          "size": "3.3GB",
          "context": "256K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "qwen3-vl:2b",
          "name": "2b",
          "parameters": "2B",
          "size": "1.9GB",
          "context": "256K",
          "vision": true,
          "input_types": "Text, Image"
        }
      ],
      "vision": true,
      "ollamaUrl": "https://ollama.com/library/qwen3-vl",
      "downloads": 1000000
    },
    {
      "description": "Phi 4 reasoning and reasoning plus are 14-billion parameter open-weight reasoning models that rival much larger models on complex reasoning tasks. ",
      "id": "phi4-reasoning",
      "name": "Phi4 Reasoning",
      "variants": [
        {
          "id": "phi4-reasoning:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "11GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "phi4-reasoning:14b",
          "name": "14b",
          "parameters": "14B",
          "size": "11GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/phi4-reasoning",
      "downloads": 984600
    },
    {
      "description": "Magistral is a small, efficient reasoning model with 24B parameters.",
      "id": "magistral",
      "name": "Magistral",
      "variants": [
        {
          "id": "magistral:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "14GB",
          "context": "39K",
          "vision": false
        },
        {
          "id": "magistral:24b",
          "name": "24b",
          "parameters": "24B",
          "size": "14GB",
          "context": "39K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/magistral",
      "downloads": 934700
    },
    {
      "description": "Phi-2: a 2.7B language model by Microsoft Research that demonstrates outstanding reasoning and language understanding capabilities.",
      "id": "phi",
      "name": "Phi",
      "variants": [
        {
          "id": "phi:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "1.6GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "phi:2.7b",
          "name": "2.7b",
          "parameters": "2.7B",
          "size": "1.6GB",
          "context": "2K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/phi",
      "downloads": 888700
    },
    {
      "description": "Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of experts models that excels at coding tasks. Created by Eric Hartford.",
      "id": "dolphin-mixtral",
      "name": "Dolphin Mixtral",
      "variants": [
        {
          "id": "dolphin-mixtral:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "26GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "dolphin-mixtral:8x22b",
          "name": "8x22b",
          "parameters": "22B",
          "size": "80GB",
          "context": "64K",
          "vision": false
        },
        {
          "id": "dolphin-mixtral:8x7b",
          "name": "8x7b",
          "parameters": "7B",
          "size": "26GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/dolphin-mixtral",
      "downloads": 850100
    },
    {
      "description": "IBM Granite 2B and 8B models are 128K context length language models that have been fine-tuned for improved reasoning and instruction-following capabilities.",
      "id": "granite3.3",
      "name": "Granite3.3",
      "variants": [
        {
          "id": "granite3.3:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.9GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "granite3.3:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "4.9GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "granite3.3:2b",
          "name": "2b",
          "parameters": "2B",
          "size": "1.5GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/granite3.3",
      "downloads": 817600
    },
    {
      "description": "Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on Llama 3 that has a variety of instruction, conversational, and coding skills.",
      "id": "dolphin-llama3",
      "name": "Dolphin Llama3",
      "variants": [
        {
          "id": "dolphin-llama3:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.7GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "dolphin-llama3:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "40GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "dolphin-llama3:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "4.7GB",
          "context": "8K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/dolphin-llama3",
      "downloads": 764500
    },
    {
      "description": "Phi-4-mini brings significant enhancements in multilingual support, reasoning, and mathematics, and now, the long-awaited function calling feature is finally supported.",
      "id": "phi4-mini",
      "name": "Phi4 Mini",
      "variants": [
        {
          "id": "phi4-mini:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "2.5GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "phi4-mini:3.8b",
          "name": "3.8b",
          "parameters": "3.8B",
          "size": "2.5GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/phi4-mini",
      "downloads": 735600
    },
    {
      "description": "A fully open-source family of reasoning models built using a dataset derived by distilling DeepSeek-R1.",
      "id": "openthinker",
      "name": "Openthinker",
      "variants": [
        {
          "id": "openthinker:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.7GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openthinker:32b",
          "name": "32b",
          "parameters": "32B",
          "size": "20GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openthinker:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.7GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/openthinker",
      "downloads": 682000
    },
    {
      "description": "ü™ê A family of small models with 135M, 360M, and 1.7B parameters, trained on a new high-quality dataset.",
      "id": "smollm",
      "name": "Smollm",
      "variants": [
        {
          "id": "smollm:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "991MB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "smollm:360m",
          "name": "360m",
          "parameters": "360M",
          "size": "229MB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "smollm:135m",
          "name": "135m",
          "parameters": "135M",
          "size": "92MB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "smollm:1.7b",
          "name": "1.7b",
          "parameters": "1.7B",
          "size": "991MB",
          "context": "2K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/smollm",
      "downloads": 676900
    },
    {
      "description": "Codestral is Mistral AI‚Äôs first-ever code model designed for code generation tasks.",
      "id": "codestral",
      "name": "Codestral",
      "variants": [
        {
          "id": "codestral:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "13GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "codestral:22b",
          "name": "22b",
          "parameters": "22B",
          "size": "13GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/codestral",
      "downloads": 668000
    },
    {
      "description": "A compact and efficient vision-language model, specifically designed for visual document understanding, enabling automated content extraction from tables, charts, infographics, plots, diagrams, and more.",
      "id": "granite3.2-vision",
      "name": "Granite3.2 Vision",
      "variants": [
        {
          "id": "granite3.2-vision:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "2.4GB",
          "context": "16K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "granite3.2-vision:2b",
          "name": "2b",
          "parameters": "2B",
          "size": "2.4GB",
          "context": "16K",
          "vision": true,
          "input_types": "Text, Image"
        }
      ],
      "vision": true,
      "ollamaUrl": "https://ollama.com/library/granite3.2-vision",
      "downloads": 632600
    },
    {
      "description": "Devstral: the best open source model for coding agents",
      "id": "devstral",
      "name": "Devstral",
      "variants": [
        {
          "id": "devstral:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "14GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "devstral:24b",
          "name": "24b",
          "parameters": "24B",
          "size": "14GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/devstral",
      "downloads": 623200
    },
    {
      "description": "The uncensored Dolphin model based on Mistral that excels at coding tasks. Updated to version 2.8.",
      "id": "dolphin-mistral",
      "name": "Dolphin Mistral",
      "variants": [
        {
          "id": "dolphin-mistral:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "dolphin-mistral:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/dolphin-mistral",
      "downloads": 536600
    },
    {
      "description": "State of the art large language model from Microsoft AI with improved performance on complex chat, multilingual, reasoning and agent use cases.",
      "id": "wizardlm2",
      "name": "Wizardlm2",
      "variants": [
        {
          "id": "wizardlm2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "wizardlm2:8x22b",
          "name": "8x22b",
          "parameters": "22B",
          "size": "80GB",
          "context": "64K",
          "vision": false
        },
        {
          "id": "wizardlm2:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/wizardlm2",
      "downloads": 531700
    },
    {
      "description": "DeepCoder is a fully open-Source 14B coder model at O3-mini level, with a 1.5B version also available.",
      "id": "deepcoder",
      "name": "Deepcoder",
      "variants": [
        {
          "id": "deepcoder:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "9.0GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "deepcoder:14b",
          "name": "14b",
          "parameters": "14B",
          "size": "9.0GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "deepcoder:1.5b",
          "name": "1.5b",
          "parameters": "1.5B",
          "size": "1.1GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/deepcoder",
      "downloads": 520600
    },
    {
      "description": "moondream2 is a small vision language model designed to run efficiently on edge devices.",
      "id": "moondream",
      "name": "Moondream",
      "variants": [
        {
          "id": "moondream:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "1.7GB",
          "context": "2K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "moondream:1.8b",
          "name": "1.8b",
          "parameters": "1.8B",
          "size": "1.7GB",
          "context": "2K",
          "vision": true,
          "input_types": "Text, Image"
        }
      ],
      "vision": true,
      "ollamaUrl": "https://ollama.com/library/moondream",
      "downloads": 509800
    },
    {
      "description": "Command R is a Large Language Model optimized for conversational interaction and long context tasks.",
      "id": "command-r",
      "name": "Command R",
      "variants": [
        {
          "id": "command-r:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "19GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "command-r:35b",
          "name": "35b",
          "parameters": "35B",
          "size": "19GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/command-r",
      "downloads": 507400
    },
    {
      "description": "Building upon Mistral Small 3, Mistral Small 3.1 (2503) adds state-of-the-art vision understanding and enhances long context capabilities up to 128k tokens without compromising text performance.",
      "id": "mistral-small3.1",
      "name": "Mistral Small3.1",
      "variants": [
        {
          "id": "mistral-small3.1:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "15GB",
          "context": "128K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "mistral-small3.1:24b",
          "name": "24b",
          "parameters": "24B",
          "size": "15GB",
          "context": "128K",
          "vision": true,
          "input_types": "Text, Image"
        }
      ],
      "vision": true,
      "ollamaUrl": "https://ollama.com/library/mistral-small3.1",
      "downloads": 499200
    },
    {
      "description": "A family of open foundation models by IBM for Code Intelligence",
      "id": "granite-code",
      "name": "Granite Code",
      "variants": [
        {
          "id": "granite-code:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "2.0GB",
          "context": "125K",
          "vision": false
        },
        {
          "id": "granite-code:34b",
          "name": "34b",
          "parameters": "34B",
          "size": "19GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "granite-code:20b",
          "name": "20b",
          "parameters": "20B",
          "size": "12GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "granite-code:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "4.6GB",
          "context": "125K",
          "vision": false
        },
        {
          "id": "granite-code:3b",
          "name": "3b",
          "parameters": "3B",
          "size": "2.0GB",
          "context": "125K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/granite-code",
      "downloads": 496500
    },
    {
      "description": "Granite 4 features improved instruction following (IF) and tool-calling capabilities, making them more effective in enterprise applications.",
      "id": "granite4",
      "name": "Granite4",
      "variants": [
        {
          "id": "granite4:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "2.1GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "granite4:350m",
          "name": "350m",
          "parameters": "350M",
          "size": "708MB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "granite4:3b",
          "name": "3b",
          "parameters": "3B",
          "size": "2.1GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "granite4:1b",
          "name": "1b",
          "parameters": "1B",
          "size": "3.3GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/granite4",
      "downloads": 455700
    },
    {
      "description": "Hermes 3 is the latest version of the flagship Hermes series of LLMs by Nous Research",
      "id": "hermes3",
      "name": "Hermes3",
      "variants": [
        {
          "id": "hermes3:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.7GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "hermes3:405b",
          "name": "405b",
          "parameters": "405B",
          "size": "229GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "hermes3:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "40GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "hermes3:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "4.7GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "hermes3:3b",
          "name": "3b",
          "parameters": "3B",
          "size": "2.0GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/hermes3",
      "downloads": 440900
    },
    {
      "description": "A lightweight AI model with 3.8 billion parameters with performance overtaking similarly and larger sized models.",
      "id": "phi3.5",
      "name": "Phi3.5",
      "variants": [
        {
          "id": "phi3.5:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "2.2GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "phi3.5:3.8b",
          "name": "3.8b",
          "parameters": "3.8B",
          "size": "2.2GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/phi3.5",
      "downloads": 429000
    },
    {
      "description": "BakLLaVA is a multimodal model consisting of the Mistral 7B base model augmented with the LLaVA  architecture.",
      "id": "bakllava",
      "name": "Bakllava",
      "variants": [
        {
          "id": "bakllava:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.7GB",
          "context": "32K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "bakllava:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.7GB",
          "context": "32K",
          "vision": true,
          "input_types": "Text, Image"
        }
      ],
      "vision": true,
      "ollamaUrl": "https://ollama.com/library/bakllava",
      "downloads": 412100
    },
    {
      "description": "Yi 1.5 is a high-performing, bilingual language model.",
      "id": "yi",
      "name": "Yi",
      "variants": [
        {
          "id": "yi:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.5GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "yi:34b",
          "name": "34b",
          "parameters": "34B",
          "size": "19GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "yi:9b",
          "name": "9b",
          "parameters": "9B",
          "size": "5.0GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "yi:6b",
          "name": "6b",
          "parameters": "6B",
          "size": "3.5GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/yi",
      "downloads": 401600
    },
    {
      "description": "Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models that are trained to act as helpful assistants.",
      "id": "zephyr",
      "name": "Zephyr",
      "variants": [
        {
          "id": "zephyr:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "zephyr:141b",
          "name": "141b",
          "parameters": "141B",
          "size": "80GB",
          "context": "64K",
          "vision": false
        },
        {
          "id": "zephyr:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/zephyr",
      "downloads": 384600
    },
    {
      "description": "EXAONE Deep exhibits superior capabilities in various reasoning tasks including math and coding benchmarks, ranging from 2.4B to 32B parameters developed and released by LG AI Research.",
      "id": "exaone-deep",
      "name": "Exaone Deep",
      "variants": [
        {
          "id": "exaone-deep:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.8GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "exaone-deep:32b",
          "name": "32b",
          "parameters": "32B",
          "size": "19GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "exaone-deep:7.8b",
          "name": "7.8b",
          "parameters": "7.8B",
          "size": "4.8GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "exaone-deep:2.4b",
          "name": "2.4b",
          "parameters": "2.4B",
          "size": "1.6GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/exaone-deep",
      "downloads": 370500
    },
    {
      "description": "Mistral Large 2 is Mistral's new flagship model that is significantly more capable in code generation, mathematics, and reasoning with 128k context window and support for dozens of languages.",
      "id": "mistral-large",
      "name": "Mistral Large",
      "variants": [
        {
          "id": "mistral-large:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "73GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "mistral-large:123b",
          "name": "123b",
          "parameters": "123B",
          "size": "73GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/mistral-large",
      "downloads": 368500
    },
    {
      "description": "EmbeddingGemma is a 300M parameter embedding model from Google.",
      "id": "embeddinggemma",
      "name": "Embeddinggemma",
      "variants": [
        {
          "id": "embeddinggemma:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "622MB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "embeddinggemma:300m",
          "name": "300m",
          "parameters": "300M",
          "size": "622MB",
          "context": "2K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/embeddinggemma",
      "downloads": 364700,
      "model_type": "embedding"
    },
    {
      "description": "Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on Llama 2 uncensored by Eric Hartford.",
      "id": "wizard-vicuna-uncensored",
      "name": "Wizard Vicuna Uncensored",
      "variants": [
        {
          "id": "wizard-vicuna-uncensored:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.8GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizard-vicuna-uncensored:30b",
          "name": "30b",
          "parameters": "30B",
          "size": "18GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizard-vicuna-uncensored:13b",
          "name": "13b",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizard-vicuna-uncensored:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "3.8GB",
          "context": "2K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/wizard-vicuna-uncensored",
      "downloads": 358200
    },
    {
      "description": "StarCoder is a code generation model trained on 80&#43; programming languages.",
      "id": "starcoder",
      "name": "Starcoder",
      "variants": [
        {
          "id": "starcoder:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "1.8GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "starcoder:15b",
          "name": "15b",
          "parameters": "15B",
          "size": "9.0GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "starcoder:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.3GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "starcoder:3b",
          "name": "3b",
          "parameters": "3B",
          "size": "1.8GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "starcoder:1b",
          "name": "1b",
          "parameters": "1B",
          "size": "726MB",
          "context": "8K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/starcoder",
      "downloads": 320700
    },
    {
      "description": "OpenCoder is an open and reproducible code LLM family which includes 1.5B and 8B models, supporting chat in English and Chinese languages.",
      "id": "opencoder",
      "name": "Opencoder",
      "variants": [
        {
          "id": "opencoder:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.7GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "opencoder:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "4.7GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "opencoder:1.5b",
          "name": "1.5b",
          "parameters": "1.5B",
          "size": "1.4GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/opencoder",
      "downloads": 320400
    },
    {
      "description": "General use models based on Llama and Llama 2 from Nous Research.",
      "id": "nous-hermes",
      "name": "Nous Hermes",
      "variants": [
        {
          "id": "nous-hermes:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.8GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "nous-hermes:13b",
          "name": "13b",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "nous-hermes:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "3.8GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/nous-hermes",
      "downloads": 315400
    },
    {
      "description": "An advanced language model crafted with 2 trillion bilingual tokens.",
      "id": "deepseek-llm",
      "name": "Deepseek Llm",
      "variants": [
        {
          "id": "deepseek-llm:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.0GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "deepseek-llm:67b",
          "name": "67b",
          "parameters": "67B",
          "size": "38GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "deepseek-llm:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.0GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/deepseek-llm",
      "downloads": 306100
    },
    {
      "description": "A large language model built by the Technology Innovation Institute (TII) for use in summarization, text generation, and chat bots.",
      "id": "falcon",
      "name": "Falcon",
      "variants": [
        {
          "id": "falcon:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.2GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "falcon:180b",
          "name": "180b",
          "parameters": "180B",
          "size": "101GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "falcon:40b",
          "name": "40b",
          "parameters": "40B",
          "size": "24GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "falcon:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.2GB",
          "context": "2K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/falcon",
      "downloads": 306000
    },
    {
      "description": "A family of open-source models trained on a wide variety of data, surpassing ChatGPT on various benchmarks. Updated to version 3.5-0106.",
      "id": "openchat",
      "name": "Openchat",
      "variants": [
        {
          "id": "openchat:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.1GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "openchat:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "8K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/openchat",
      "downloads": 299600
    },
    {
      "description": "General use chat model based on Llama and Llama 2 with 2K to 16K context sizes.",
      "id": "vicuna",
      "name": "Vicuna",
      "variants": [
        {
          "id": "vicuna:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.8GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "vicuna:33b",
          "name": "33b",
          "parameters": "33B",
          "size": "18GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "vicuna:13b",
          "name": "13b",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "vicuna:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "3.8GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/vicuna",
      "downloads": 298100
    },
    {
      "description": "A strong, economical, and efficient Mixture-of-Experts language model.",
      "id": "deepseek-v2",
      "name": "Deepseek V2",
      "variants": [
        {
          "id": "deepseek-v2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "8.9GB",
          "context": "160K",
          "vision": false
        },
        {
          "id": "deepseek-v2:236b",
          "name": "236b",
          "parameters": "236B",
          "size": "133GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "deepseek-v2:16b",
          "name": "16b",
          "parameters": "16B",
          "size": "8.9GB",
          "context": "160K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/deepseek-v2",
      "downloads": 297700
    },
    {
      "description": "Sentence-transformers model that can be used for tasks like clustering or semantic search.",
      "id": "paraphrase-multilingual",
      "name": "Paraphrase Multilingual",
      "variants": [
        {
          "id": "paraphrase-multilingual:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "563MB",
          "context": "512",
          "vision": false
        },
        {
          "id": "paraphrase-multilingual:278m",
          "name": "278m",
          "parameters": "278M",
          "size": "563MB",
          "context": "512",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/paraphrase-multilingual",
      "downloads": 287700
    },
    {
      "description": "OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully open datasets.",
      "id": "openhermes",
      "name": "Openhermes",
      "variants": [
        {
          "id": "openhermes:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2-q2_k",
          "name": "7b-mistral-v2-q2_k",
          "parameters": "7B",
          "size": "3.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2-q3_k_s",
          "name": "7b-mistral-v2-q3_k_s",
          "parameters": "7B",
          "size": "3.2GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2-q3_k_m",
          "name": "7b-mistral-v2-q3_k_m",
          "parameters": "7B",
          "size": "3.5GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2-q3_k_l",
          "name": "7b-mistral-v2-q3_k_l",
          "parameters": "7B",
          "size": "3.8GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2-q4_0",
          "name": "7b-mistral-v2-q4_0",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2-q4_1",
          "name": "7b-mistral-v2-q4_1",
          "parameters": "7B",
          "size": "4.6GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2-q4_k_s",
          "name": "7b-mistral-v2-q4_k_s",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2-q4_k_m",
          "name": "7b-mistral-v2-q4_k_m",
          "parameters": "7B",
          "size": "4.4GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2-q5_0",
          "name": "7b-mistral-v2-q5_0",
          "parameters": "7B",
          "size": "5.0GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2-q5_1",
          "name": "7b-mistral-v2-q5_1",
          "parameters": "7B",
          "size": "5.4GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2-q5_k_s",
          "name": "7b-mistral-v2-q5_k_s",
          "parameters": "7B",
          "size": "5.0GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2-q5_k_m",
          "name": "7b-mistral-v2-q5_k_m",
          "parameters": "7B",
          "size": "5.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2-q6_k",
          "name": "7b-mistral-v2-q6_k",
          "parameters": "7B",
          "size": "5.9GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2-q8_0",
          "name": "7b-mistral-v2-q8_0",
          "parameters": "7B",
          "size": "7.7GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2-fp16",
          "name": "7b-mistral-v2-fp16",
          "parameters": "7B",
          "size": "14GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2.5-q2_k",
          "name": "7b-mistral-v2.5-q2_k",
          "parameters": "7B",
          "size": "3.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2.5-q3_k_s",
          "name": "7b-mistral-v2.5-q3_k_s",
          "parameters": "7B",
          "size": "3.2GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2.5-q3_k_m",
          "name": "7b-mistral-v2.5-q3_k_m",
          "parameters": "7B",
          "size": "3.5GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2.5-q3_k_l",
          "name": "7b-mistral-v2.5-q3_k_l",
          "parameters": "7B",
          "size": "3.8GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2.5-q4_0",
          "name": "7b-mistral-v2.5-q4_0",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2.5-q4_1",
          "name": "7b-mistral-v2.5-q4_1",
          "parameters": "7B",
          "size": "4.6GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2.5-q4_k_s",
          "name": "7b-mistral-v2.5-q4_k_s",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2.5-q4_k_m",
          "name": "7b-mistral-v2.5-q4_k_m",
          "parameters": "7B",
          "size": "4.4GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2.5-q5_0",
          "name": "7b-mistral-v2.5-q5_0",
          "parameters": "7B",
          "size": "5.0GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2.5-q5_1",
          "name": "7b-mistral-v2.5-q5_1",
          "parameters": "7B",
          "size": "5.4GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2.5-q5_k_s",
          "name": "7b-mistral-v2.5-q5_k_s",
          "parameters": "7B",
          "size": "5.0GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2.5-q5_k_m",
          "name": "7b-mistral-v2.5-q5_k_m",
          "parameters": "7B",
          "size": "5.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2.5-q6_k",
          "name": "7b-mistral-v2.5-q6_k",
          "parameters": "7B",
          "size": "5.9GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2.5-q8_0",
          "name": "7b-mistral-v2.5-q8_0",
          "parameters": "7B",
          "size": "7.7GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-mistral-v2.5-fp16",
          "name": "7b-mistral-v2.5-fp16",
          "parameters": "7B",
          "size": "14GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-v2",
          "name": "7b-v2",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:7b-v2.5",
          "name": "7b-v2.5",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:v2",
          "name": "v2",
          "parameters": "Unknown",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "openhermes:v2.5",
          "name": "v2.5",
          "parameters": "Unknown",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/openhermes",
      "downloads": 279800
    },
    {
      "description": "CodeQwen1.5 is a large language model pretrained on a large amount of code data.",
      "id": "codeqwen",
      "name": "Codeqwen",
      "variants": [
        {
          "id": "codeqwen:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.2GB",
          "context": "64K",
          "vision": false
        },
        {
          "id": "codeqwen:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.2GB",
          "context": "64K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/codeqwen",
      "downloads": 278500
    },
    {
      "description": "Qwen2 Math is a series of specialized math language models built upon the Qwen2 LLMs, which significantly outperforms the mathematical capabilities of open-source models and even closed-source models (e.g., GPT4o).",
      "id": "qwen2-math",
      "name": "Qwen2 Math",
      "variants": [
        {
          "id": "qwen2-math:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.4GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "qwen2-math:72b",
          "name": "72b",
          "parameters": "72B",
          "size": "41GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "qwen2-math:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.4GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "qwen2-math:1.5b",
          "name": "1.5b",
          "parameters": "1.5B",
          "size": "935MB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/qwen2-math",
      "downloads": 266500
    },
    {
      "description": "Building upon the foundational models of the Qwen3 series, Qwen3 Embedding provides a comprehensive range of text embeddings models in various sizes",
      "id": "qwen3-embedding",
      "name": "Qwen3 Embedding",
      "variants": [
        {
          "id": "qwen3-embedding:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.7GB",
          "context": "40K",
          "vision": false
        },
        {
          "id": "qwen3-embedding:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "4.7GB",
          "context": "40K",
          "vision": false
        },
        {
          "id": "qwen3-embedding:4b",
          "name": "4b",
          "parameters": "4B",
          "size": "2.5GB",
          "context": "40K",
          "vision": false
        },
        {
          "id": "qwen3-embedding:0.6b",
          "name": "0.6b",
          "parameters": "0.6B",
          "size": "639MB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/qwen3-embedding",
      "downloads": 262300,
      "model_type": "embedding"
    },
    {
      "description": "A strong multi-lingual general language model with competitive performance to Llama 3.",
      "id": "glm4",
      "name": "Glm4",
      "variants": [
        {
          "id": "glm4:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "5.5GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "glm4:9b",
          "name": "9b",
          "parameters": "9B",
          "size": "5.5GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/glm4",
      "downloads": 261500
    },
    {
      "description": "Aya 23, released by Cohere, is a new family of state-of-the-art, multilingual models that support 23 languages. ",
      "id": "aya",
      "name": "Aya",
      "variants": [
        {
          "id": "aya:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.8GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "aya:35b",
          "name": "35b",
          "parameters": "35B",
          "size": "20GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "aya:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "4.8GB",
          "context": "8K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/aya",
      "downloads": 259800
    },
    {
      "description": "Llama 2 based model fine tuned to improve Chinese dialogue ability.",
      "id": "llama2-chinese",
      "name": "Llama2 Chinese",
      "variants": [
        {
          "id": "llama2-chinese:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.8GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama2-chinese:13b",
          "name": "13b",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama2-chinese:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "3.8GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/llama2-chinese",
      "downloads": 256900
    },
    {
      "description": "Command R&#43; is a powerful, scalable large language model purpose-built to excel at real-world enterprise use cases.",
      "id": "command-r-plus",
      "name": "Command R Plus",
      "variants": [
        {
          "id": "command-r-plus:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "59GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "command-r-plus:104b",
          "name": "104b",
          "parameters": "104B",
          "size": "59GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/command-r-plus",
      "downloads": 253800
    },
    {
      "description": "DeepSeek-V3.1-Terminus is a hybrid model that supports both thinking mode and non-thinking mode.",
      "id": "deepseek-v3.1",
      "name": "Deepseek V3.1",
      "variants": [
        {
          "id": "deepseek-v3.1:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "404GB",
          "context": "160K",
          "vision": false
        },
        {
          "id": "deepseek-v3.1:671b",
          "name": "671b",
          "parameters": "671B",
          "size": "404GB",
          "context": "160K",
          "vision": false
        },
        {
          "id": "deepseek-v3.1:671b-cloud",
          "name": "671b-cloud",
          "parameters": "671B",
          "size": "Cloud (API only)",
          "context": "160K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/deepseek-v3.1",
      "downloads": 252300
    },
    {
      "description": "A versatile model for AI software development scenarios, including code completion.",
      "id": "codegeex4",
      "name": "Codegeex4",
      "variants": [
        {
          "id": "codegeex4:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "5.5GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "codegeex4:9b",
          "name": "9b",
          "parameters": "9B",
          "size": "5.5GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/codegeex4",
      "downloads": 251300
    },
    {
      "description": "Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the Mistral 7B model using the OpenOrca dataset.",
      "id": "mistral-openorca",
      "name": "Mistral Openorca",
      "variants": [
        {
          "id": "mistral-openorca:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "mistral-openorca:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/mistral-openorca",
      "downloads": 250200
    },
    {
      "description": "Stable Code 3B is a coding model with instruct and code completion variants on par with models such as Code Llama 7B that are 2.5x larger.",
      "id": "stable-code",
      "name": "Stable Code",
      "variants": [
        {
          "id": "stable-code:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "1.6GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "stable-code:3b",
          "name": "3b",
          "parameters": "3B",
          "size": "1.6GB",
          "context": "16K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/stable-code",
      "downloads": 248700
    },
    {
      "description": "A fine-tuned model based on Mistral with good coverage of domain and language.",
      "id": "neural-chat",
      "name": "Neural Chat",
      "variants": [
        {
          "id": "neural-chat:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "neural-chat:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/neural-chat",
      "downloads": 244900
    },
    {
      "description": "The first installment in the Qwen3-Next series with strong performance in terms of both parameter efficiency and inference speed.",
      "id": "qwen3-next",
      "name": "Qwen3 Next",
      "variants": [
        {
          "id": "qwen3-next:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "50GB",
          "context": "256K",
          "vision": false
        },
        {
          "id": "qwen3-next:80b",
          "name": "80b",
          "parameters": "80B",
          "size": "50GB",
          "context": "256K",
          "vision": false
        },
        {
          "id": "qwen3-next:80b-cloud",
          "name": "80b-cloud",
          "parameters": "80B",
          "size": "Cloud (API only)",
          "context": "256K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/qwen3-next",
      "downloads": 243700
    },
    {
      "description": "The powerful family of models by Nous Research that excels at scientific discussion and coding tasks.",
      "id": "nous-hermes2",
      "name": "Nous Hermes2",
      "variants": [
        {
          "id": "nous-hermes2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "6.1GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "nous-hermes2:34b",
          "name": "34b",
          "parameters": "34B",
          "size": "19GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "nous-hermes2:10.7b",
          "name": "10.7b",
          "parameters": "10.7B",
          "size": "6.1GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/nous-hermes2",
      "downloads": 242800
    },
    {
      "description": "An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset by Eric Hartford and based on TinyLlama.",
      "id": "tinydolphin",
      "name": "Tinydolphin",
      "variants": [
        {
          "id": "tinydolphin:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "637MB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "tinydolphin:1.1b",
          "name": "1.1b",
          "parameters": "1.1B",
          "size": "637MB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/tinydolphin",
      "downloads": 238200
    },
    {
      "description": "State-of-the-art code generation model",
      "id": "wizardcoder",
      "name": "Wizardcoder",
      "variants": [
        {
          "id": "wizardcoder:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.8GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "wizardcoder:33b",
          "name": "33b",
          "parameters": "33B",
          "size": "19GB",
          "context": "16K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/wizardcoder",
      "downloads": 237800
    },
    {
      "description": "SQLCoder is a code completion model fined-tuned on StarCoder for SQL generation tasks",
      "id": "sqlcoder",
      "name": "Sqlcoder",
      "variants": [
        {
          "id": "sqlcoder:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "sqlcoder:15b",
          "name": "15b",
          "parameters": "15B",
          "size": "9.0GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "sqlcoder:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/sqlcoder",
      "downloads": 235200
    },
    {
      "description": "Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model trained on multilingual data in English, Spanish, German, Italian, French, Portuguese, and Dutch.",
      "id": "stablelm2",
      "name": "Stablelm2",
      "variants": [
        {
          "id": "stablelm2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "983MB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "stablelm2:12b",
          "name": "12b",
          "parameters": "12B",
          "size": "7.0GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "stablelm2:1.6b",
          "name": "1.6b",
          "parameters": "1.6B",
          "size": "983MB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/stablelm2",
      "downloads": 225200
    },
    {
      "description": "Yi-Coder is a series of open-source code language models that delivers state-of-the-art coding performance with fewer than 10 billion parameters.",
      "id": "yi-coder",
      "name": "Yi Coder",
      "variants": [
        {
          "id": "yi-coder:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "5.0GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "yi-coder:9b",
          "name": "9b",
          "parameters": "9B",
          "size": "5.0GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "yi-coder:1.5b",
          "name": "1.5b",
          "parameters": "1.5B",
          "size": "866MB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/yi-coder",
      "downloads": 224400
    },
    {
      "description": "A model from NVIDIA based on Llama 3 that excels at conversational question answering (QA) and retrieval-augmented generation (RAG).",
      "id": "llama3-chatqa",
      "name": "Llama3 Chatqa",
      "variants": [
        {
          "id": "llama3-chatqa:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.7GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "llama3-chatqa:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "40GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "llama3-chatqa:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "4.7GB",
          "context": "8K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/llama3-chatqa",
      "downloads": 222300
    },
    {
      "description": "Snowflake's frontier embedding model. Arctic Embed 2.0 adds multilingual support without sacrificing English performance or scalability.",
      "id": "snowflake-arctic-embed2",
      "name": "Snowflake Arctic Embed2",
      "variants": [
        {
          "id": "snowflake-arctic-embed2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "1.2GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "snowflake-arctic-embed2:568m",
          "name": "568m",
          "parameters": "568M",
          "size": "1.2GB",
          "context": "8K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/snowflake-arctic-embed2",
      "downloads": 220800,
      "model_type": "embedding"
    },
    {
      "description": "The IBM Granite 2B and 8B models are designed to support tool-based use cases and support for retrieval augmented generation (RAG), streamlining code generation, translation and bug fixing.",
      "id": "granite3-dense",
      "name": "Granite3 Dense",
      "variants": [
        {
          "id": "granite3-dense:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "1.6GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "granite3-dense:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "4.9GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "granite3-dense:2b",
          "name": "2b",
          "parameters": "2B",
          "size": "1.6GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/granite3-dense",
      "downloads": 219300
    },
    {
      "description": "The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 trillion tokens of data, demonstrated significant improvements over their predecessors in performance and speed in IBM‚Äôs initial testing.",
      "id": "granite3.1-dense",
      "name": "Granite3.1 Dense",
      "variants": [
        {
          "id": "granite3.1-dense:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "5.0GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "granite3.1-dense:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "5.0GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "granite3.1-dense:2b",
          "name": "2b",
          "parameters": "2B",
          "size": "1.6GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/granite3.1-dense",
      "downloads": 218600
    },
    {
      "description": "The Ministral 3 family is designed for edge deployment, capable of running on a wide range of hardware.",
      "id": "ministral-3",
      "name": "Ministral 3",
      "variants": [
        {
          "id": "ministral-3:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "6.0GB",
          "context": "256K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "ministral-3:14b",
          "name": "14b",
          "parameters": "14B",
          "size": "9.1GB",
          "context": "256K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "ministral-3:14b-cloud",
          "name": "14b-cloud",
          "parameters": "14B",
          "size": "Cloud (API only)",
          "context": "256K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "ministral-3:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "6.0GB",
          "context": "256K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "ministral-3:8b-cloud",
          "name": "8b-cloud",
          "parameters": "8B",
          "size": "Cloud (API only)",
          "context": "256K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "ministral-3:3b",
          "name": "3b",
          "parameters": "3B",
          "size": "3.0GB",
          "context": "256K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "ministral-3:3b-cloud",
          "name": "3b-cloud",
          "parameters": "3B",
          "size": "Cloud (API only)",
          "context": "256K",
          "vision": true,
          "input_types": "Text, Image"
        }
      ],
      "vision": true,
      "ollamaUrl": "https://ollama.com/library/ministral-3",
      "downloads": 215000
    },
    {
      "description": "Granite-3.2 is a family of long-context AI models from IBM Granite fine-tuned for thinking capabilities.",
      "id": "granite3.2",
      "name": "Granite3.2",
      "variants": [
        {
          "id": "granite3.2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.9GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "granite3.2:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "4.9GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "granite3.2:2b",
          "name": "2b",
          "parameters": "2B",
          "size": "1.5GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/granite3.2",
      "downloads": 212500
    },
    {
      "description": "Model focused on math and logic problems",
      "id": "wizard-math",
      "name": "Wizard Math",
      "variants": [
        {
          "id": "wizard-math:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "wizard-math:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "39GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizard-math:13b",
          "name": "13b",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizard-math:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/wizard-math",
      "downloads": 210100
    },
    {
      "description": "A 7B and 15B uncensored variant of the Dolphin model family that excels at coding, based on StarCoder2.",
      "id": "dolphincoder",
      "name": "Dolphincoder",
      "variants": [
        {
          "id": "dolphincoder:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.2GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "dolphincoder:15b",
          "name": "15b",
          "parameters": "15B",
          "size": "9.1GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "dolphincoder:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.2GB",
          "context": "16K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/dolphincoder",
      "downloads": 208500
    },
    {
      "description": "This model extends LLama-3 8B's context length from 8k to over 1m tokens.",
      "id": "llama3-gradient",
      "name": "Llama3 Gradient",
      "variants": [
        {
          "id": "llama3-gradient:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.7GB",
          "context": "1M",
          "vision": false
        },
        {
          "id": "llama3-gradient:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "40GB",
          "context": "1M",
          "vision": false
        },
        {
          "id": "llama3-gradient:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "4.7GB",
          "context": "1M",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/llama3-gradient",
      "downloads": 208400
    },
    {
      "description": "A companion assistant trained in philosophy, psychology, and personal relationships. Based on Mistral.",
      "id": "samantha-mistral",
      "name": "Samantha Mistral",
      "variants": [
        {
          "id": "samantha-mistral:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "samantha-mistral:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/samantha-mistral",
      "downloads": 205400
    },
    {
      "description": "InternLM2.5 is a 7B parameter model tailored for practical scenarios with outstanding reasoning capability.",
      "id": "internlm2",
      "name": "Internlm2",
      "variants": [
        {
          "id": "internlm2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.5GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "internlm2:20b",
          "name": "20b",
          "parameters": "20B",
          "size": "11GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "internlm2:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.5GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "internlm2:1.8b",
          "name": "1.8b",
          "parameters": "1.8B",
          "size": "1.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "internlm2:1m",
          "name": "1m",
          "parameters": "1M",
          "size": "4.5GB",
          "context": "256K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/internlm2",
      "downloads": 198600
    },
    {
      "description": "A series of models from Groq that represent a significant advancement in open-source AI capabilities for tool use/function calling.",
      "id": "llama3-groq-tool-use",
      "name": "Llama3 Groq Tool Use",
      "variants": [
        {
          "id": "llama3-groq-tool-use:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.7GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "llama3-groq-tool-use:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "40GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "llama3-groq-tool-use:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "4.7GB",
          "context": "8K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/llama3-groq-tool-use",
      "downloads": 193700
    },
    {
      "description": "Starling is a large language model trained by reinforcement learning from AI feedback focused on improving chatbot helpfulness.",
      "id": "starling-lm",
      "name": "Starling Lm",
      "variants": [
        {
          "id": "starling-lm:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.1GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "starling-lm:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "8K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/starling-lm",
      "downloads": 193000
    },
    {
      "description": "Code generation model based on Code Llama.",
      "id": "phind-codellama",
      "name": "Phind Codellama",
      "variants": [
        {
          "id": "phind-codellama:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "19GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "phind-codellama:34b",
          "name": "34b",
          "parameters": "34B",
          "size": "19GB",
          "context": "16K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/phind-codellama",
      "downloads": 191800
    },
    {
      "description": "A compact, yet powerful 10.7B large language model designed for single-turn conversation.",
      "id": "solar",
      "name": "Solar",
      "variants": [
        {
          "id": "solar:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "6.1GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "solar:10.7b",
          "name": "10.7b",
          "parameters": "10.7B",
          "size": "6.1GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/solar",
      "downloads": 191000
    },
    {
      "description": "Llama Guard 3 is a series of models fine-tuned for content safety classification of LLM inputs and responses.",
      "id": "llama-guard3",
      "name": "Llama Guard3",
      "variants": [
        {
          "id": "llama-guard3:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.9GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "llama-guard3:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "4.9GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "llama-guard3:1b",
          "name": "1b",
          "parameters": "1B",
          "size": "1.6GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/llama-guard3",
      "downloads": 188700
    },
    {
      "description": "Conversational model based on Llama 2 that performs competitively on various benchmarks.",
      "id": "xwinlm",
      "name": "Xwinlm",
      "variants": [
        {
          "id": "xwinlm:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.8GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "xwinlm:13b",
          "name": "13b",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "xwinlm:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "3.8GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/xwinlm",
      "downloads": 188600
    },
    {
      "description": "A version of the DeepSeek-R1 model that has been post trained to provide unbiased, accurate, and factual information by Perplexity. ",
      "id": "r1-1776",
      "name": "R1.1776",
      "variants": [
        {
          "id": "r1-1776:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "43GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "r1-1776:671b",
          "name": "671b",
          "parameters": "671B",
          "size": "404GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "r1-1776:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "43GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/r1-1776",
      "downloads": 183500
    },
    {
      "description": "Cohere For AI's language models trained to perform well across 23 different languages.",
      "id": "aya-expanse",
      "name": "Aya Expanse",
      "variants": [
        {
          "id": "aya-expanse:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "5.1GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "aya-expanse:32b",
          "name": "32b",
          "parameters": "32B",
          "size": "20GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "aya-expanse:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "5.1GB",
          "context": "8K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/aya-expanse",
      "downloads": 183200
    },
    {
      "description": "A high-performing model trained with a new technique called Reflection-tuning that teaches a LLM to detect mistakes in its reasoning and correct course.",
      "id": "reflection",
      "name": "Reflection",
      "variants": [
        {
          "id": "reflection:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "40GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "reflection:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "40GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/reflection",
      "downloads": 182700
    },
    {
      "description": "An extension of Llama 2 that supports a context of up to 128k tokens.",
      "id": "yarn-llama2",
      "name": "Yarn Llama2",
      "variants": [
        {
          "id": "yarn-llama2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.8GB",
          "context": "64K",
          "vision": false
        },
        {
          "id": "yarn-llama2:13b",
          "name": "13b",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "64K",
          "vision": false
        },
        {
          "id": "yarn-llama2:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "3.8GB",
          "context": "64K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/yarn-llama2",
      "downloads": 182100
    },
    {
      "description": "The IBM Granite 1B and 3B models are the first mixture of experts (MoE) Granite models from IBM designed for low latency usage.",
      "id": "granite3-moe",
      "name": "Granite3 Moe",
      "variants": [
        {
          "id": "granite3-moe:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "822MB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "granite3-moe:3b",
          "name": "3b",
          "parameters": "3B",
          "size": "2.1GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "granite3-moe:1b",
          "name": "1b",
          "parameters": "1B",
          "size": "822MB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/granite3-moe",
      "downloads": 181000
    },
    {
      "description": "EXAONE 3.5 is a collection of instruction-tuned bilingual (English and Korean) generative models ranging from 2.4B to 32B parameters, developed and released by LG AI Research. ",
      "id": "exaone3.5",
      "name": "Exaone3.5",
      "variants": [
        {
          "id": "exaone3.5:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.8GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "exaone3.5:32b",
          "name": "32b",
          "parameters": "32B",
          "size": "19GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "exaone3.5:7.8b",
          "name": "7.8b",
          "parameters": "7.8B",
          "size": "4.8GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "exaone3.5:2.4b",
          "name": "2.4b",
          "parameters": "2.4B",
          "size": "1.6GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/exaone3.5",
      "downloads": 179400
    },
    {
      "description": "Embedding model from BAAI mapping texts to vectors.",
      "id": "bge-large",
      "name": "Bge Large",
      "variants": [
        {
          "id": "bge-large:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "671MB",
          "context": "512",
          "vision": false
        },
        {
          "id": "bge-large:335m",
          "name": "335m",
          "parameters": "335M",
          "size": "671MB",
          "context": "512",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/bge-large",
      "downloads": 175100,
      "model_type": "embedding"
    },
    {
      "description": "A commercial-friendly small language model by NVIDIA optimized for roleplay, RAG QA, and function calling.",
      "id": "nemotron-mini",
      "name": "Nemotron Mini",
      "variants": [
        {
          "id": "nemotron-mini:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "2.7GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "nemotron-mini:4b",
          "name": "4b",
          "parameters": "4B",
          "size": "2.7GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/nemotron-mini",
      "downloads": 173800
    },
    {
      "description": "Orca 2 is built by Microsoft research, and are a fine-tuned version of Meta's Llama 2 models.  The model is designed to excel particularly in reasoning.",
      "id": "orca2",
      "name": "Orca2",
      "variants": [
        {
          "id": "orca2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.8GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "orca2:13b",
          "name": "13b",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "orca2:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "3.8GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/orca2",
      "downloads": 168800
    },
    {
      "description": "A new small LLaVA model fine-tuned from Phi 3 Mini.",
      "id": "llava-phi3",
      "name": "Llava Phi3",
      "variants": [
        {
          "id": "llava-phi3:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "2.9GB",
          "context": "4K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "llava-phi3:3.8b",
          "name": "3.8b",
          "parameters": "3.8B",
          "size": "2.9GB",
          "context": "4K",
          "vision": true,
          "input_types": "Text, Image"
        }
      ],
      "vision": true,
      "ollamaUrl": "https://ollama.com/library/llava-phi3",
      "downloads": 168700
    },
    {
      "description": "Open-source medical large language model adapted from Llama 2 to the medical domain.",
      "id": "meditron",
      "name": "Meditron",
      "variants": [
        {
          "id": "meditron:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.8GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "meditron:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "39GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "meditron:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "3.8GB",
          "context": "2K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/meditron",
      "downloads": 168000
    },
    {
      "description": "Athene-V2 is a 72B parameter model which excels at code completion, mathematics, and log extraction tasks.",
      "id": "athene-v2",
      "name": "Athene V2",
      "variants": [
        {
          "id": "athene-v2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "47GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "athene-v2:72b",
          "name": "72b",
          "parameters": "72B",
          "size": "47GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/athene-v2",
      "downloads": 164000
    },
    {
      "description": "The IBM Granite Embedding 30M and 278M models models are text-only dense biencoder embedding models, with 30M available in English only and 278M serving multilingual use cases.",
      "id": "granite-embedding",
      "name": "Granite Embedding",
      "variants": [
        {
          "id": "granite-embedding:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "63MB",
          "context": "512",
          "vision": false
        },
        {
          "id": "granite-embedding:278m",
          "name": "278m",
          "parameters": "278M",
          "size": "563MB",
          "context": "512",
          "vision": false
        },
        {
          "id": "granite-embedding:30m",
          "name": "30m",
          "parameters": "30M",
          "size": "63MB",
          "context": "512",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/granite-embedding",
      "downloads": 161900,
      "model_type": "embedding"
    },
    {
      "description": "Llama 2 based model fine tuned on an Orca-style dataset. Originally called Free Willy.",
      "id": "stable-beluga",
      "name": "Stable Beluga",
      "variants": [
        {
          "id": "stable-beluga:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.8GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "stable-beluga:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "39GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "stable-beluga:13b",
          "name": "13b",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "stable-beluga:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "3.8GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/stable-beluga",
      "downloads": 161900
    },
    {
      "description": "Llama-3.1-Nemotron-70B-Instruct is a large language model customized by NVIDIA to improve the helpfulness of LLM generated responses to user queries.",
      "id": "nemotron",
      "name": "Nemotron",
      "variants": [
        {
          "id": "nemotron:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "43GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "nemotron:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "43GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/nemotron",
      "downloads": 160000
    },
    {
      "description": "Uncensored version of Wizard LM model ",
      "id": "wizardlm-uncensored",
      "name": "Wizardlm Uncensored",
      "variants": [
        {
          "id": "wizardlm-uncensored:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "7.4GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm-uncensored:13b",
          "name": "13b",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/wizardlm-uncensored",
      "downloads": 156900
    },
    {
      "description": "A series of models that convert HTML content to Markdown content, which is useful for content conversion tasks.",
      "id": "reader-lm",
      "name": "Reader Lm",
      "variants": [
        {
          "id": "reader-lm:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "935MB",
          "context": "250K",
          "vision": false
        },
        {
          "id": "reader-lm:1.5b",
          "name": "1.5b",
          "parameters": "1.5B",
          "size": "935MB",
          "context": "250K",
          "vision": false
        },
        {
          "id": "reader-lm:0.5b",
          "name": "0.5b",
          "parameters": "0.5B",
          "size": "352MB",
          "context": "250K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/reader-lm",
      "downloads": 156000
    },
    {
      "description": "T√ºlu 3 is a leading instruction following model family, offering fully open-source data, code, and recipes by the The Allen Institute for AI.",
      "id": "tulu3",
      "name": "Tulu3",
      "variants": [
        {
          "id": "tulu3:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.9GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "tulu3:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "43GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "tulu3:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "4.9GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/tulu3",
      "downloads": 151300
    },
    {
      "description": "ShieldGemma is set of instruction tuned models for evaluating the safety of text prompt input and text output responses against a set of defined safety policies.",
      "id": "shieldgemma",
      "name": "Shieldgemma",
      "variants": [
        {
          "id": "shieldgemma:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "5.8GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "shieldgemma:27b",
          "name": "27b",
          "parameters": "27B",
          "size": "17GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "shieldgemma:9b",
          "name": "9b",
          "parameters": "9B",
          "size": "5.8GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "shieldgemma:2b",
          "name": "2b",
          "parameters": "2B",
          "size": "1.7GB",
          "context": "8K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/shieldgemma",
      "downloads": 151000
    },
    {
      "description": "DBRX is an open, general-purpose LLM created by Databricks.",
      "id": "dbrx",
      "name": "Dbrx",
      "variants": [
        {
          "id": "dbrx:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "74GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "dbrx:132b",
          "name": "132b",
          "parameters": "132B",
          "size": "74GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/dbrx",
      "downloads": 149600
    },
    {
      "description": "An expansion of Llama 2 that specializes in integrating both general language understanding and domain-specific knowledge, particularly in programming and mathematics.",
      "id": "llama-pro",
      "name": "Llama Pro",
      "variants": [
        {
          "id": "llama-pro:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.7GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-instruct-q2_k",
          "name": "8b-instruct-q2_k",
          "parameters": "8B",
          "size": "3.5GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-instruct-q3_k_s",
          "name": "8b-instruct-q3_k_s",
          "parameters": "8B",
          "size": "3.6GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-instruct-q3_k_m",
          "name": "8b-instruct-q3_k_m",
          "parameters": "8B",
          "size": "4.1GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-instruct-q3_k_l",
          "name": "8b-instruct-q3_k_l",
          "parameters": "8B",
          "size": "4.5GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-instruct-q4_0",
          "name": "8b-instruct-q4_0",
          "parameters": "8B",
          "size": "4.7GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-instruct-q4_1",
          "name": "8b-instruct-q4_1",
          "parameters": "8B",
          "size": "5.3GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-instruct-q4_k_s",
          "name": "8b-instruct-q4_k_s",
          "parameters": "8B",
          "size": "4.8GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-instruct-q4_k_m",
          "name": "8b-instruct-q4_k_m",
          "parameters": "8B",
          "size": "5.1GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-instruct-q5_0",
          "name": "8b-instruct-q5_0",
          "parameters": "8B",
          "size": "5.8GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-instruct-q5_1",
          "name": "8b-instruct-q5_1",
          "parameters": "8B",
          "size": "6.3GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-instruct-q5_k_s",
          "name": "8b-instruct-q5_k_s",
          "parameters": "8B",
          "size": "5.8GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-instruct-q5_k_m",
          "name": "8b-instruct-q5_k_m",
          "parameters": "8B",
          "size": "5.9GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-instruct-q6_k",
          "name": "8b-instruct-q6_k",
          "parameters": "8B",
          "size": "6.9GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-instruct-q8_0",
          "name": "8b-instruct-q8_0",
          "parameters": "8B",
          "size": "8.9GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-instruct-fp16",
          "name": "8b-instruct-fp16",
          "parameters": "8B",
          "size": "17GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-text-q2_k",
          "name": "8b-text-q2_k",
          "parameters": "8B",
          "size": "3.5GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-text-q3_k_s",
          "name": "8b-text-q3_k_s",
          "parameters": "8B",
          "size": "3.6GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-text-q3_k_m",
          "name": "8b-text-q3_k_m",
          "parameters": "8B",
          "size": "4.1GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-text-q3_k_l",
          "name": "8b-text-q3_k_l",
          "parameters": "8B",
          "size": "4.5GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-text-q4_0",
          "name": "8b-text-q4_0",
          "parameters": "8B",
          "size": "4.7GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-text-q4_1",
          "name": "8b-text-q4_1",
          "parameters": "8B",
          "size": "5.3GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-text-q4_k_s",
          "name": "8b-text-q4_k_s",
          "parameters": "8B",
          "size": "4.8GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-text-q4_k_m",
          "name": "8b-text-q4_k_m",
          "parameters": "8B",
          "size": "5.1GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-text-q5_0",
          "name": "8b-text-q5_0",
          "parameters": "8B",
          "size": "5.8GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-text-q5_1",
          "name": "8b-text-q5_1",
          "parameters": "8B",
          "size": "6.3GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-text-q5_k_s",
          "name": "8b-text-q5_k_s",
          "parameters": "8B",
          "size": "5.8GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-text-q5_k_m",
          "name": "8b-text-q5_k_m",
          "parameters": "8B",
          "size": "5.9GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-text-q6_k",
          "name": "8b-text-q6_k",
          "parameters": "8B",
          "size": "6.9GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-text-q8_0",
          "name": "8b-text-q8_0",
          "parameters": "8B",
          "size": "8.9GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:8b-text-fp16",
          "name": "8b-text-fp16",
          "parameters": "8B",
          "size": "17GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:instruct",
          "name": "instruct",
          "parameters": "Unknown",
          "size": "4.7GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "llama-pro:text",
          "name": "text",
          "parameters": "Unknown",
          "size": "4.7GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/llama-pro",
      "downloads": 148600
    },
    {
      "description": "An extension of Mistral to support context windows of 64K or 128K.",
      "id": "yarn-mistral",
      "name": "Yarn Mistral",
      "variants": [
        {
          "id": "yarn-mistral:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "yarn-mistral:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/yarn-mistral",
      "downloads": 146000
    },
    {
      "description": "General use model based on Llama 2.",
      "id": "wizardlm",
      "name": "Wizardlm",
      "variants": [
        {
          "id": "wizardlm:70b-llama2-q2_k",
          "name": "70b-llama2-q2_k",
          "parameters": "70B",
          "size": "29GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:70b-llama2-q3_k_s",
          "name": "70b-llama2-q3_k_s",
          "parameters": "70B",
          "size": "30GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:70b-llama2-q3_k_m",
          "name": "70b-llama2-q3_k_m",
          "parameters": "70B",
          "size": "33GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:70b-llama2-q3_k_l",
          "name": "70b-llama2-q3_k_l",
          "parameters": "70B",
          "size": "36GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:70b-llama2-q4_0",
          "name": "70b-llama2-q4_0",
          "parameters": "70B",
          "size": "39GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:70b-llama2-q4_1",
          "name": "70b-llama2-q4_1",
          "parameters": "70B",
          "size": "43GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:70b-llama2-q4_k_s",
          "name": "70b-llama2-q4_k_s",
          "parameters": "70B",
          "size": "39GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:70b-llama2-q4_k_m",
          "name": "70b-llama2-q4_k_m",
          "parameters": "70B",
          "size": "41GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:70b-llama2-q5_0",
          "name": "70b-llama2-q5_0",
          "parameters": "70B",
          "size": "47GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:70b-llama2-q5_k_s",
          "name": "70b-llama2-q5_k_s",
          "parameters": "70B",
          "size": "47GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:70b-llama2-q5_k_m",
          "name": "70b-llama2-q5_k_m",
          "parameters": "70B",
          "size": "49GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:70b-llama2-q6_k",
          "name": "70b-llama2-q6_k",
          "parameters": "70B",
          "size": "57GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:70b-llama2-q8_0",
          "name": "70b-llama2-q8_0",
          "parameters": "70B",
          "size": "73GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:30b-q2_k",
          "name": "30b-q2_k",
          "parameters": "30B",
          "size": "14GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:30b-q3_k_s",
          "name": "30b-q3_k_s",
          "parameters": "30B",
          "size": "14GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:30b-q3_k_m",
          "name": "30b-q3_k_m",
          "parameters": "30B",
          "size": "16GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:30b-q3_k_l",
          "name": "30b-q3_k_l",
          "parameters": "30B",
          "size": "17GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:30b-q4_0",
          "name": "30b-q4_0",
          "parameters": "30B",
          "size": "18GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:30b-q4_1",
          "name": "30b-q4_1",
          "parameters": "30B",
          "size": "20GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:30b-q4_k_s",
          "name": "30b-q4_k_s",
          "parameters": "30B",
          "size": "18GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:30b-q4_k_m",
          "name": "30b-q4_k_m",
          "parameters": "30B",
          "size": "20GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:30b-q5_0",
          "name": "30b-q5_0",
          "parameters": "30B",
          "size": "22GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:30b-q5_1",
          "name": "30b-q5_1",
          "parameters": "30B",
          "size": "24GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:30b-q5_k_s",
          "name": "30b-q5_k_s",
          "parameters": "30B",
          "size": "22GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:30b-q5_k_m",
          "name": "30b-q5_k_m",
          "parameters": "30B",
          "size": "23GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:30b-q6_k",
          "name": "30b-q6_k",
          "parameters": "30B",
          "size": "27GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:30b-q8_0",
          "name": "30b-q8_0",
          "parameters": "30B",
          "size": "35GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:30b-fp16",
          "name": "30b-fp16",
          "parameters": "30B",
          "size": "65GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-llama2-q2_k",
          "name": "13b-llama2-q2_k",
          "parameters": "13B",
          "size": "5.4GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-llama2-q3_k_s",
          "name": "13b-llama2-q3_k_s",
          "parameters": "13B",
          "size": "5.7GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-llama2-q3_k_m",
          "name": "13b-llama2-q3_k_m",
          "parameters": "13B",
          "size": "6.3GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-llama2-q3_k_l",
          "name": "13b-llama2-q3_k_l",
          "parameters": "13B",
          "size": "6.9GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-llama2-q4_0",
          "name": "13b-llama2-q4_0",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-llama2-q4_1",
          "name": "13b-llama2-q4_1",
          "parameters": "13B",
          "size": "8.2GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-llama2-q4_k_s",
          "name": "13b-llama2-q4_k_s",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-llama2-q4_k_m",
          "name": "13b-llama2-q4_k_m",
          "parameters": "13B",
          "size": "7.9GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-llama2-q5_0",
          "name": "13b-llama2-q5_0",
          "parameters": "13B",
          "size": "9.0GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-llama2-q5_1",
          "name": "13b-llama2-q5_1",
          "parameters": "13B",
          "size": "9.8GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-llama2-q5_k_s",
          "name": "13b-llama2-q5_k_s",
          "parameters": "13B",
          "size": "9.0GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-llama2-q5_k_m",
          "name": "13b-llama2-q5_k_m",
          "parameters": "13B",
          "size": "9.2GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-llama2-q6_k",
          "name": "13b-llama2-q6_k",
          "parameters": "13B",
          "size": "11GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-llama2-q8_0",
          "name": "13b-llama2-q8_0",
          "parameters": "13B",
          "size": "14GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-llama2-fp16",
          "name": "13b-llama2-fp16",
          "parameters": "13B",
          "size": "26GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-q2_k",
          "name": "13b-q2_k",
          "parameters": "13B",
          "size": "5.4GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-q3_k_s",
          "name": "13b-q3_k_s",
          "parameters": "13B",
          "size": "5.7GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-q3_k_m",
          "name": "13b-q3_k_m",
          "parameters": "13B",
          "size": "6.3GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-q3_k_l",
          "name": "13b-q3_k_l",
          "parameters": "13B",
          "size": "6.9GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-q4_0",
          "name": "13b-q4_0",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-q4_1",
          "name": "13b-q4_1",
          "parameters": "13B",
          "size": "8.2GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-q4_k_s",
          "name": "13b-q4_k_s",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-q4_k_m",
          "name": "13b-q4_k_m",
          "parameters": "13B",
          "size": "7.9GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-q5_0",
          "name": "13b-q5_0",
          "parameters": "13B",
          "size": "9.0GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-q5_1",
          "name": "13b-q5_1",
          "parameters": "13B",
          "size": "9.8GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-q5_k_s",
          "name": "13b-q5_k_s",
          "parameters": "13B",
          "size": "9.0GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-q5_k_m",
          "name": "13b-q5_k_m",
          "parameters": "13B",
          "size": "9.2GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-q6_k",
          "name": "13b-q6_k",
          "parameters": "13B",
          "size": "11GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-q8_0",
          "name": "13b-q8_0",
          "parameters": "13B",
          "size": "14GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:13b-fp16",
          "name": "13b-fp16",
          "parameters": "13B",
          "size": "26GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:7b-q2_k",
          "name": "7b-q2_k",
          "parameters": "7B",
          "size": "2.8GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:7b-q3_k_s",
          "name": "7b-q3_k_s",
          "parameters": "7B",
          "size": "2.9GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:7b-q3_k_m",
          "name": "7b-q3_k_m",
          "parameters": "7B",
          "size": "3.3GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:7b-q3_k_l",
          "name": "7b-q3_k_l",
          "parameters": "7B",
          "size": "3.6GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:7b-q4_0",
          "name": "7b-q4_0",
          "parameters": "7B",
          "size": "3.8GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:7b-q4_1",
          "name": "7b-q4_1",
          "parameters": "7B",
          "size": "4.2GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:7b-q4_k_s",
          "name": "7b-q4_k_s",
          "parameters": "7B",
          "size": "3.9GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:7b-q4_k_m",
          "name": "7b-q4_k_m",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:7b-q5_0",
          "name": "7b-q5_0",
          "parameters": "7B",
          "size": "4.7GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:7b-q5_1",
          "name": "7b-q5_1",
          "parameters": "7B",
          "size": "5.1GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:7b-q5_k_s",
          "name": "7b-q5_k_s",
          "parameters": "7B",
          "size": "4.7GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:7b-q5_k_m",
          "name": "7b-q5_k_m",
          "parameters": "7B",
          "size": "4.8GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:7b-q6_k",
          "name": "7b-q6_k",
          "parameters": "7B",
          "size": "5.5GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:7b-q8_0",
          "name": "7b-q8_0",
          "parameters": "7B",
          "size": "7.2GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizardlm:7b-fp16",
          "name": "7b-fp16",
          "parameters": "7B",
          "size": "13GB",
          "context": "2K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/wizardlm",
      "downloads": 143700
    },
    {
      "description": "Nexus Raven is a 13B instruction tuned model for function calling tasks. ",
      "id": "nexusraven",
      "name": "Nexusraven",
      "variants": [
        {
          "id": "nexusraven:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "7.4GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "nexusraven:13b",
          "name": "13b",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "16K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/nexusraven",
      "downloads": 143300
    },
    {
      "description": "Fine-tuned Llama 2 model to answer medical questions based on an open source medical dataset. ",
      "id": "medllama2",
      "name": "Medllama2",
      "variants": [
        {
          "id": "medllama2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.8GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "medllama2:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "3.8GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/medllama2",
      "downloads": 140600
    },
    {
      "description": "The Nous Hermes 2 model from Nous Research, now trained over Mixtral.",
      "id": "nous-hermes2-mixtral",
      "name": "Nous Hermes2 Mixtral",
      "variants": [
        {
          "id": "nous-hermes2-mixtral:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "26GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "nous-hermes2-mixtral:8x7b",
          "name": "8x7b",
          "parameters": "7B",
          "size": "26GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/nous-hermes2-mixtral",
      "downloads": 138200
    },
    {
      "description": "A new small reasoning model fine-tuned from the Qwen 2.5 3B Instruct model.",
      "id": "smallthinker",
      "name": "Smallthinker",
      "variants": [
        {
          "id": "smallthinker:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.6GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "smallthinker:3b",
          "name": "3b",
          "parameters": "3B",
          "size": "3.6GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/smallthinker",
      "downloads": 121700
    },
    {
      "description": "Great code generation model based on Llama2.",
      "id": "codeup",
      "name": "Codeup",
      "variants": [
        {
          "id": "codeup:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "7.4GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "codeup:13b",
          "name": "13b",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/codeup",
      "downloads": 119800
    },
    {
      "description": "MathŒ£tral: a 7B model designed for math reasoning and scientific discovery by Mistral AI.",
      "id": "mathstral",
      "name": "Mathstral",
      "variants": [
        {
          "id": "mathstral:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "mathstral:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/mathstral",
      "downloads": 119800
    },
    {
      "description": "Uncensored Llama2 based model with support for a 16K context window.",
      "id": "everythinglm",
      "name": "Everythinglm",
      "variants": [
        {
          "id": "everythinglm:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "7.4GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "everythinglm:13b",
          "name": "13b",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "16K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/everythinglm",
      "downloads": 118900
    },
    {
      "description": "Phi 4 mini reasoning is a lightweight open model that balances efficiency with advanced reasoning ability.",
      "id": "phi4-mini-reasoning",
      "name": "Phi4 Mini Reasoning",
      "variants": [
        {
          "id": "phi4-mini-reasoning:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.2GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "phi4-mini-reasoning:3.8b",
          "name": "3.8b",
          "parameters": "3.8B",
          "size": "3.2GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/phi4-mini-reasoning",
      "downloads": 114100
    },
    {
      "description": "The smallest model in Cohere's R series delivers top-tier speed, efficiency, and quality to build powerful AI applications on commodity GPUs and edge devices.",
      "id": "command-r7b",
      "name": "Command R7b",
      "variants": [
        {
          "id": "command-r7b:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "5.1GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "command-r7b:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "5.1GB",
          "context": "8K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/command-r7b",
      "downloads": 113800
    },
    {
      "description": "A lightweight chat model allowing accurate, and responsive output without requiring high-end hardware.",
      "id": "stablelm-zephyr",
      "name": "Stablelm Zephyr",
      "variants": [
        {
          "id": "stablelm-zephyr:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "1.6GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "stablelm-zephyr:3b",
          "name": "3b",
          "parameters": "3B",
          "size": "1.6GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/stablelm-zephyr",
      "downloads": 113300
    },
    {
      "description": "Solar Pro Preview: an advanced large language model (LLM) with 22 billion parameters designed to fit into a single GPU",
      "id": "solar-pro",
      "name": "Solar Pro",
      "variants": [
        {
          "id": "solar-pro:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "13GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "solar-pro:22b",
          "name": "22b",
          "parameters": "22B",
          "size": "13GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/solar-pro",
      "downloads": 113000
    },
    {
      "description": "Falcon2 is an 11B parameters causal decoder-only model built by TII and trained over 5T tokens.",
      "id": "falcon2",
      "name": "Falcon2",
      "variants": [
        {
          "id": "falcon2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "6.4GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "falcon2:11b",
          "name": "11b",
          "parameters": "11B",
          "size": "6.4GB",
          "context": "2K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/falcon2",
      "downloads": 111900
    },
    {
      "description": "An upgraded version of DeekSeek-V2  that integrates the general and coding abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct.",
      "id": "deepseek-v2.5",
      "name": "Deepseek V2.5",
      "variants": [
        {
          "id": "deepseek-v2.5:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "133GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "deepseek-v2.5:236b",
          "name": "236b",
          "parameters": "236B",
          "size": "133GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/deepseek-v2.5",
      "downloads": 109900
    },
    {
      "description": "7B parameter text-to-SQL model made by MotherDuck and Numbers Station.",
      "id": "duckdb-nsql",
      "name": "Duckdb Nsql",
      "variants": [
        {
          "id": "duckdb-nsql:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.8GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "duckdb-nsql:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "3.8GB",
          "context": "16K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/duckdb-nsql",
      "downloads": 109200
    },
    {
      "description": "üé© Magicoder is a family of 7B parameter models trained on 75K synthetic instruction data using OSS-Instruct, a novel approach to enlightening LLMs with open-source code snippets.",
      "id": "magicoder",
      "name": "Magicoder",
      "variants": [
        {
          "id": "magicoder:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "3.8GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "magicoder:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "3.8GB",
          "context": "16K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/magicoder",
      "downloads": 109000
    },
    {
      "description": "MistralLite is a fine-tuned model based on Mistral with enhanced capabilities of processing long contexts.",
      "id": "mistrallite",
      "name": "Mistrallite",
      "variants": [
        {
          "id": "mistrallite:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "mistrallite:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/mistrallite",
      "downloads": 107000
    },
    {
      "description": "A state-of-the-art fact-checking model developed by Bespoke Labs.",
      "id": "bespoke-minicheck",
      "name": "Bespoke Minicheck",
      "variants": [
        {
          "id": "bespoke-minicheck:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.7GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "bespoke-minicheck:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.7GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/bespoke-minicheck",
      "downloads": 106200
    },
    {
      "description": "A 3.8B model fine-tuned on a private high-quality synthetic dataset for information extraction, based on Phi-3.",
      "id": "nuextract",
      "name": "Nuextract",
      "variants": [
        {
          "id": "nuextract:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "2.2GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "nuextract:3.8b",
          "name": "3.8b",
          "parameters": "3.8B",
          "size": "2.2GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/nuextract",
      "downloads": 106100
    },
    {
      "description": "A high-performing code instruct model created by merging two existing code models.",
      "id": "codebooga",
      "name": "Codebooga",
      "variants": [
        {
          "id": "codebooga:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "19GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "codebooga:34b",
          "name": "34b",
          "parameters": "34B",
          "size": "19GB",
          "context": "16K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/codebooga",
      "downloads": 104300
    },
    {
      "description": "Wizard Vicuna is a 13B parameter model based on Llama 2 trained by MelodysDreamj.",
      "id": "wizard-vicuna",
      "name": "Wizard Vicuna",
      "variants": [
        {
          "id": "wizard-vicuna:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "7.4GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "wizard-vicuna:13b",
          "name": "13b",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "2K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/wizard-vicuna",
      "downloads": 102600
    },
    {
      "description": "MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by interleaving the model with itself.",
      "id": "megadolphin",
      "name": "Megadolphin",
      "variants": [
        {
          "id": "megadolphin:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "68GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "megadolphin:120b",
          "name": "120b",
          "parameters": "120B",
          "size": "68GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/megadolphin",
      "downloads": 101200
    },
    {
      "description": "A top-performing mixture of experts model, fine-tuned with high-quality data.",
      "id": "notux",
      "name": "Notux",
      "variants": [
        {
          "id": "notux:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "26GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "notux:8x7b",
          "name": "8x7b",
          "parameters": "7B",
          "size": "26GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/notux",
      "downloads": 98400
    },
    {
      "description": "An open weights function calling model based on Llama 3, competitive with GPT-4o function calling capabilities.",
      "id": "firefunction-v2",
      "name": "Firefunction V2",
      "variants": [
        {
          "id": "firefunction-v2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "40GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "firefunction-v2:70b",
          "name": "70b",
          "parameters": "70B",
          "size": "40GB",
          "context": "8K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/firefunction-v2",
      "downloads": 98100
    },
    {
      "description": "111 billion parameter model optimized for demanding enterprises that require fast, secure, and high-quality AI",
      "id": "command-a",
      "name": "Command A",
      "variants": [
        {
          "id": "command-a:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "67GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "command-a:111b",
          "name": "111b",
          "parameters": "111B",
          "size": "67GB",
          "context": "16K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/command-a",
      "downloads": 97600
    },
    {
      "description": "A 7B chat model fine-tuned with high-quality data and based on Zephyr.",
      "id": "notus",
      "name": "Notus",
      "variants": [
        {
          "id": "notus:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "notus:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.1GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/notus",
      "downloads": 97600
    },
    {
      "description": "DeepSeek-OCR is a vision-language model that can perform token-efficient OCR.",
      "id": "deepseek-ocr",
      "name": "Deepseek Ocr",
      "variants": [
        {
          "id": "deepseek-ocr:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "6.7GB",
          "context": "8K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "deepseek-ocr:3b",
          "name": "3b",
          "parameters": "3B",
          "size": "6.7GB",
          "context": "8K",
          "vision": true,
          "input_types": "Text, Image"
        }
      ],
      "vision": true,
      "ollamaUrl": "https://ollama.com/library/deepseek-ocr",
      "downloads": 96200
    },
    {
      "description": "Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. Designed for chat and code generation.",
      "id": "open-orca-platypus2",
      "name": "Open Orca Platypus2",
      "variants": [
        {
          "id": "open-orca-platypus2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "7.4GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "open-orca-platypus2:13b",
          "name": "13b",
          "parameters": "13B",
          "size": "7.4GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/open-orca-platypus2",
      "downloads": 96100
    },
    {
      "description": "Nemotron 3 Nano - A new Standard for Efficient, Open, and Intelligent Agentic Models",
      "id": "nemotron-3-nano",
      "name": "Nemotron 3 Nano",
      "variants": [
        {
          "id": "nemotron-3-nano:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "24GB",
          "context": "1M",
          "vision": false
        },
        {
          "id": "nemotron-3-nano:30b",
          "name": "30b",
          "parameters": "30B",
          "size": "24GB",
          "context": "1M",
          "vision": false
        },
        {
          "id": "nemotron-3-nano:30b-cloud",
          "name": "30b-cloud",
          "parameters": "30B",
          "size": "Cloud (API only)",
          "context": "1M",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/nemotron-3-nano",
      "downloads": 93200
    },
    {
      "description": "A language model created by combining two fine-tuned Llama 2 70B models into one.",
      "id": "goliath",
      "name": "Goliath",
      "variants": [
        {
          "id": "goliath:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "66GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "goliath:120b-q2_k",
          "name": "120b-q2_k",
          "parameters": "120B",
          "size": "50GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "goliath:120b-q3_k_s",
          "name": "120b-q3_k_s",
          "parameters": "120B",
          "size": "51GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "goliath:120b-q3_k_m",
          "name": "120b-q3_k_m",
          "parameters": "120B",
          "size": "56GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "goliath:120b-q3_k_l",
          "name": "120b-q3_k_l",
          "parameters": "120B",
          "size": "62GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "goliath:120b-q4_0",
          "name": "120b-q4_0",
          "parameters": "120B",
          "size": "66GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "goliath:120b-q4_1",
          "name": "120b-q4_1",
          "parameters": "120B",
          "size": "74GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "goliath:120b-q4_k_s",
          "name": "120b-q4_k_s",
          "parameters": "120B",
          "size": "66GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "goliath:120b-q4_k_m",
          "name": "120b-q4_k_m",
          "parameters": "120B",
          "size": "71GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "goliath:120b-q5_0",
          "name": "120b-q5_0",
          "parameters": "120B",
          "size": "81GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "goliath:120b-q5_1",
          "name": "120b-q5_1",
          "parameters": "120B",
          "size": "88GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "goliath:120b-q5_k_s",
          "name": "120b-q5_k_s",
          "parameters": "120B",
          "size": "81GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "goliath:120b-q5_k_m",
          "name": "120b-q5_k_m",
          "parameters": "120B",
          "size": "83GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "goliath:120b-q6_k",
          "name": "120b-q6_k",
          "parameters": "120B",
          "size": "97GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "goliath:120b-q8_0",
          "name": "120b-q8_0",
          "parameters": "120B",
          "size": "125GB",
          "context": "4K",
          "vision": false
        },
        {
          "id": "goliath:120b-fp16",
          "name": "120b-fp16",
          "parameters": "120B",
          "size": "236GB",
          "context": "4K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/goliath",
      "downloads": 91700
    },
    {
      "description": "An open large reasoning model for real-world solutions by the Alibaba International Digital Commerce Group (AIDC-AI).",
      "id": "marco-o1",
      "name": "Marco O1",
      "variants": [
        {
          "id": "marco-o1:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.7GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "marco-o1:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.7GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/marco-o1",
      "downloads": 87900
    },
    {
      "description": "Sailor2 are multilingual language models made for South-East Asia. Available in 1B, 8B, and 20B parameter sizes.",
      "id": "sailor2",
      "name": "Sailor2",
      "variants": [
        {
          "id": "sailor2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "5.2GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "sailor2:20b",
          "name": "20b",
          "parameters": "20B",
          "size": "12GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "sailor2:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "5.2GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "sailor2:1b",
          "name": "1b",
          "parameters": "1B",
          "size": "1.1GB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/sailor2",
      "downloads": 87500
    },
    {
      "description": "The IBM Granite Guardian 3.0 2B and 8B models are designed to detect risks in prompts and/or responses.",
      "id": "granite3-guardian",
      "name": "Granite3 Guardian",
      "variants": [
        {
          "id": "granite3-guardian:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "2.7GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "granite3-guardian:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "5.8GB",
          "context": "8K",
          "vision": false
        },
        {
          "id": "granite3-guardian:2b",
          "name": "2b",
          "parameters": "2B",
          "size": "2.7GB",
          "context": "8K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/granite3-guardian",
      "downloads": 85300
    },
    {
      "description": "24B model that excels at using tools to explore codebases, editing multiple files and power software engineering agents.",
      "id": "devstral-small-2",
      "name": "Devstral Small 2",
      "variants": [
        {
          "id": "devstral-small-2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "15GB",
          "context": "384K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "devstral-small-2:24b",
          "name": "24b",
          "parameters": "24B",
          "size": "15GB",
          "context": "384K",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "devstral-small-2:24b-cloud",
          "name": "24b-cloud",
          "parameters": "24B",
          "size": "Cloud (API only)",
          "context": "256K",
          "vision": true,
          "input_types": "Text, Image"
        }
      ],
      "vision": true,
      "ollamaUrl": "https://ollama.com/library/devstral-small-2",
      "downloads": 80500
    },
    {
      "description": "Google's most intelligent model with SOTA reasoning and multimodal understanding, and powerful agentic and vibe coding capabilities.",
      "id": "gemini-3-pro-preview",
      "name": "Gemini 3 Pro Preview",
      "variants": [
        {
          "id": "gemini-3-pro-preview:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "Cloud (API only)",
          "context": "1M",
          "vision": true,
          "input_types": "Text, Image"
        }
      ],
      "vision": true,
      "ollamaUrl": "https://ollama.com/library/gemini-3-pro-preview",
      "downloads": 78400
    },
    {
      "description": "A robust conversational model designed to be used for both chat and instruct use cases.",
      "id": "alfred",
      "name": "Alfred",
      "variants": [
        {
          "id": "alfred:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "24GB",
          "context": "2K",
          "vision": false
        },
        {
          "id": "alfred:40b",
          "name": "40b",
          "parameters": "40B",
          "size": "24GB",
          "context": "2K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/alfred",
      "downloads": 67600
    },
    {
      "description": "A new state-of-the-art version of the lightweight Command R7B model that excels in advanced Arabic language capabilities for enterprises in the Middle East and Northern Africa.",
      "id": "command-r7b-arabic",
      "name": "Command R7b Arabic",
      "variants": [
        {
          "id": "command-r7b-arabic:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "5.1GB",
          "context": "16K",
          "vision": false
        },
        {
          "id": "command-r7b-arabic:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "5.1GB",
          "context": "16K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/command-r7b-arabic",
      "downloads": 55400
    },
    {
      "description": "Olmo is a series of Open language models designed to enable the science of language models. These models are pre-trained on the Dolma 3 dataset and post-trained on the Dolci datasets.",
      "id": "olmo-3",
      "name": "Olmo 3",
      "variants": [
        {
          "id": "olmo-3:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "4.5GB",
          "context": "64K",
          "vision": false
        },
        {
          "id": "olmo-3:32b",
          "name": "32b",
          "parameters": "32B",
          "size": "19GB",
          "context": "64K",
          "vision": false
        },
        {
          "id": "olmo-3:7b",
          "name": "7b",
          "parameters": "7B",
          "size": "4.5GB",
          "context": "64K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/olmo-3",
      "downloads": 54700
    },
    {
      "description": "Advanced agentic, reasoning and coding capabilities.",
      "id": "glm-4.6",
      "name": "Glm 4.6",
      "variants": [
        {
          "id": "glm-4.6:cloud",
          "name": "cloud",
          "parameters": "Unknown",
          "size": "Cloud (API only)",
          "context": "198K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/glm-4.6",
      "downloads": 43800
    },
    {
      "description": "gpt-oss-safeguard-20b and gpt-oss-safeguard-120b are safety reasoning models built-upon gpt-oss",
      "id": "gpt-oss-safeguard",
      "name": "Gpt Oss Safeguard",
      "variants": [
        {
          "id": "gpt-oss-safeguard:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "14GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "gpt-oss-safeguard:120b",
          "name": "120b",
          "parameters": "120B",
          "size": "65GB",
          "context": "128K",
          "vision": false
        },
        {
          "id": "gpt-oss-safeguard:20b",
          "name": "20b",
          "parameters": "20B",
          "size": "14GB",
          "context": "128K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/gpt-oss-safeguard",
      "downloads": 43800
    },
    {
      "description": "MiniMax M2 is a high-efficiency large language model built for coding and agentic workflows.",
      "id": "minimax-m2",
      "name": "Minimax M2",
      "variants": [
        {
          "id": "minimax-m2:cloud",
          "name": "cloud",
          "parameters": "Unknown",
          "size": "Cloud (API only)",
          "context": "200K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/minimax-m2",
      "downloads": 36600
    },
    {
      "description": "123B model that excels at using tools to explore codebases, editing multiple files and power software engineering agents.",
      "id": "devstral-2",
      "name": "Devstral 2",
      "variants": [
        {
          "id": "devstral-2:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "75GB",
          "context": "256K",
          "vision": false
        },
        {
          "id": "devstral-2:123b",
          "name": "123b",
          "parameters": "123B",
          "size": "75GB",
          "context": "256K",
          "vision": false
        },
        {
          "id": "devstral-2:123b-cloud",
          "name": "123b-cloud",
          "parameters": "123B",
          "size": "Cloud (API only)",
          "context": "256K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/devstral-2",
      "downloads": 35300
    },
    {
      "description": "The Cogito v2.1 LLMs are instruction tuned generative models. All models are released under MIT license for commercial use.",
      "id": "cogito-2.1",
      "name": "Cogito 2.1",
      "variants": [
        {
          "id": "cogito-2.1:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "1.3TB",
          "context": "160K",
          "vision": false
        },
        {
          "id": "cogito-2.1:671b",
          "name": "671b",
          "parameters": "671B",
          "size": "1.3TB",
          "context": "160K",
          "vision": false
        },
        {
          "id": "cogito-2.1:671b-cloud",
          "name": "671b-cloud",
          "parameters": "671B",
          "size": "Cloud (API only)",
          "context": "160K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/cogito-2.1",
      "downloads": 34800
    },
    {
      "description": "Olmo is a series of Open language models designed to enable the science of language models. These models are pre-trained on the Dolma 3 dataset and post-trained on the Dolci datasets.",
      "id": "olmo-3.1",
      "name": "Olmo 3.1",
      "variants": [
        {
          "id": "olmo-3.1:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "19GB",
          "context": "64K",
          "vision": false
        },
        {
          "id": "olmo-3.1:32b",
          "name": "32b",
          "parameters": "32B",
          "size": "19GB",
          "context": "64K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/olmo-3.1",
      "downloads": 32300
    },
    {
      "description": "Rnj-1 is a family of 8B parameter open-weight, dense models trained from scratch by Essential AI, optimized for code and STEM with capabilities on par with SOTA open-weight models.",
      "id": "rnj-1",
      "name": "Rnj 1",
      "variants": [
        {
          "id": "rnj-1:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "5.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "rnj-1:8b",
          "name": "8b",
          "parameters": "8B",
          "size": "5.1GB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "rnj-1:8b-cloud",
          "name": "8b-cloud",
          "parameters": "8B",
          "size": "Cloud (API only)",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/rnj-1",
      "downloads": 29500
    },
    {
      "description": "FunctionGemma is a specialized version of Google's Gemma 3 270M model fine-tuned explicitly for function calling. ",
      "id": "functiongemma",
      "name": "Functiongemma",
      "variants": [
        {
          "id": "functiongemma:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "301MB",
          "context": "32K",
          "vision": false
        },
        {
          "id": "functiongemma:270m",
          "name": "270m",
          "parameters": "270M",
          "size": "301MB",
          "context": "32K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/functiongemma",
      "downloads": 28800
    },
    {
      "description": "Gemini 3 Flash offers frontier intelligence built for speed at a fraction of the cost.",
      "id": "gemini-3-flash-preview",
      "name": "Gemini 3 Flash Preview",
      "variants": [
        {
          "id": "gemini-3-flash-preview:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "Cloud (API only)",
          "context": "1M",
          "vision": true,
          "input_types": "Text, Image"
        },
        {
          "id": "gemini-3-flash-preview:cloud",
          "name": "cloud",
          "parameters": "Unknown",
          "size": "Cloud (API only)",
          "context": "1M",
          "vision": true,
          "input_types": "Text, Image"
        }
      ],
      "vision": true,
      "ollamaUrl": "https://ollama.com/library/gemini-3-flash-preview",
      "downloads": 27600
    },
    {
      "description": "A state-of-the-art mixture-of-experts (MoE) language model. Kimi K2-Instruct-0905 demonstrates significant improvements in performance on public benchmarks and real-world coding agent tasks.",
      "id": "kimi-k2",
      "name": "Kimi K2",
      "variants": [
        {
          "id": "kimi-k2:1t-cloud",
          "name": "1t-cloud",
          "parameters": "Unknown",
          "size": "Cloud (API only)",
          "context": "256K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/kimi-k2",
      "downloads": 27100
    },
    {
      "description": "Kimi K2 Thinking, Moonshot AI's best open-source thinking model.",
      "id": "kimi-k2-thinking",
      "name": "Kimi K2 Thinking",
      "variants": [
        {
          "id": "kimi-k2-thinking:cloud",
          "name": "cloud",
          "parameters": "Unknown",
          "size": "Cloud (API only)",
          "context": "256K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/kimi-k2-thinking",
      "downloads": 19500
    },
    {
      "description": "nomic-embed-text-v2-moe is a multilingual MoE text embedding model that excels at multilingual retrieval.",
      "id": "nomic-embed-text-v2-moe",
      "name": "Nomic Embed Text V2 Moe",
      "variants": [
        {
          "id": "nomic-embed-text-v2-moe:latest",
          "name": "latest",
          "parameters": "Unknown",
          "size": "958MB",
          "context": "512",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/nomic-embed-text-v2-moe",
      "downloads": 17900,
      "model_type": "embedding"
    },
    {
      "description": "DeepSeek-V3.2, a model that harmonizes high computational efficiency with superior reasoning and agent performance. ",
      "id": "deepseek-v3.2",
      "name": "Deepseek V3.2",
      "variants": [
        {
          "id": "deepseek-v3.2:cloud",
          "name": "cloud",
          "parameters": "Unknown",
          "size": "Cloud (API only)",
          "context": "160K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/deepseek-v3.2",
      "downloads": 11700
    },
    {
      "description": "Advancing the Coding Capability",
      "id": "glm-4.7",
      "name": "Glm 4.7",
      "variants": [
        {
          "id": "glm-4.7:cloud",
          "name": "cloud",
          "parameters": "Unknown",
          "size": "Cloud (API only)",
          "context": "198K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/glm-4.7",
      "downloads": 10100
    },
    {
      "description": "A general-purpose multimodal mixture-of-experts model for production-grade tasks and enterprise workloads.",
      "id": "mistral-large-3",
      "name": "Mistral Large 3",
      "variants": [
        {
          "id": "mistral-large-3:675b-cloud",
          "name": "675b-cloud",
          "parameters": "675B",
          "size": "Cloud (API only)",
          "context": "256K",
          "vision": true,
          "input_types": "Text, Image"
        }
      ],
      "vision": true,
      "ollamaUrl": "https://ollama.com/library/mistral-large-3",
      "downloads": 9
    },
    {
      "description": "Exceptional multilingual capabilities to elevate code engineering",
      "id": "minimax-m2.1",
      "name": "Minimax M2.1",
      "variants": [
        {
          "id": "minimax-m2.1:cloud",
          "name": "cloud",
          "parameters": "Unknown",
          "size": "Cloud (API only)",
          "context": "200K",
          "vision": false
        }
      ],
      "vision": false,
      "ollamaUrl": "https://ollama.com/library/minimax-m2.1",
      "downloads": 6
    }
  ]
}